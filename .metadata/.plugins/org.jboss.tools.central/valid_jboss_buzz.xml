<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0" uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title type="html">DMN Runner inputs persistence</title><link rel="alternate" href="https://blog.kie.org/2022/04/dmn-runner-inputs-persistence.html" /><author><name>Luiz Motta</name></author><id>https://blog.kie.org/2022/04/dmn-runner-inputs-persistence.html</id><updated>2022-04-22T13:48:54Z</updated><content type="html">The DMN Runner has been a fundamental part of the KIE Sandbox, and it is still evolving. In the last release, we have the pleasure to introduce a new feature that will make a huge improvement on the runner UX. The persistence of your DMN Runner inputs! Now, the KIE Sandbox saves all your inputs in your browser storage data automatically, so you don’t need to worry about losing your inputs or filing the form every time. The data will be there for you. Also, you will be able to share your inputs with your peers with the download/upload option. Let’s take a better look at it. If you wish you can follow the same steps in this post. First of all, using the “Import from URL” feature on KIE Sandbox. Then start the KIE Sandbox Extended Services. If you still don’t know how to do it, it’s simple! Click on the Run button, and follow the steps. It will start a local backend service on your machine. It enables some amazing features, such as the DMN Runner, and deploys on OpenShift. This example checks if the Driver’s Current Points are bigger than 20. If so, the Driver should be suspended. Until now, nothing has changed. Fill out the form inputs, and check the outputs. Go back to the KIE Sandbox home, and reopen the file. The inputs you just entered will be there. Check it out. Moreover, you can use the new options under the “Run” dropdown. The Download/Load options are straightforward. You’re going to download a JSON file containing your current inputs. If you wish, you can manually edit this JSON file, or you can share it with your peers. Lastly, the “Delete inputs” option will delete all your inputs, so be aware! That’s it for now. Thanks for reading and stay tuned for more updates! The post appeared first on .</content><dc:creator>Luiz Motta</dc:creator></entry><entry><title type="html">Kogito 1.20.0 released!</title><link rel="alternate" href="https://blog.kie.org/2022/04/kogito-1-20-0-released.html" /><author><name>Cristiano Nicolai</name></author><id>https://blog.kie.org/2022/04/kogito-1-20-0-released.html</id><updated>2022-04-22T01:25:16Z</updated><content type="html">We are glad to announce that the Kogito 1.20.0 release is now available! This goes hand in hand with , release. From a feature point of view, we included a series of new features and bug fixes, including: * SpringBoot upgrade to version 2.6.6 * [Serverless Workflows] Implement AuthRef property for function definitions to retrieve OpenAPI Documents * [Serverless Workflows] Support Oauth2 for legacy REST Operations * [Operator] Operator now supports users to define their own Kogito deployment using a plain k8s Deployment object by annotating it with kogito.kie.org/runtime: ‘true’. * [Operator] Operator will now create a ConfigMap for every deployed supporting service, e.g. Management Console, allowing users to configure it easily. For more details head to the complete . All artifacts are available now: * Kogito runtime artifacts are available on Maven Central. * Kogito examples can be found . * Kogito images are available on . * Kogito operator is available in the in OpenShift and Kubernetes. * Kogito tooling 0.18.0 artifacts are available at the . A detailed changelog for 1.20.0 can be found in . New to Kogito? Check out our website . Click the "Get Started" button. The post appeared first on .</content><dc:creator>Cristiano Nicolai</dc:creator></entry><entry><title type="html">This Week in JBoss - 22 April 2022</title><link rel="alternate" href="https://www.jboss.org/posts/weekly-2022-04-22.html" /><category term="quarkus" /><category term="wildfly" /><category term="resteasy" /><category term="red hat summit" /><category term="keycloak" /><category term="kogito" /><category term="elytron" /><category term="dashbuilder" /><author><name>Jason Porter</name><uri>https://www.jboss.org/people/jason-porter</uri><email>do-not-reply@jboss.com</email></author><id>https://www.jboss.org/posts/weekly-2022-04-22.html</id><updated>2022-04-22T00:00:00Z</updated><content type="html">&lt;article class="" data-tags="quarkus, wildfly, resteasy, red hat summit, keycloak, kogito, elytron, dashbuilder"&gt; &lt;h1&gt;This Week in JBoss - 22 April 2022&lt;/h1&gt; &lt;p class="preamble"&gt;&lt;/p&gt;&lt;p&gt;Welcome back! Amazing how quickly two weeks can fly by isn’t it? We have some great things for you this week including releases, tidbits from the blogoshpere, and information about Red Hat Summit 2022!&lt;/p&gt;&lt;p&gt;&lt;/p&gt; &lt;div class="sect1"&gt; &lt;h2 id="_release_roundup"&gt;Release roundup&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;Let’s jump right into what has been released over the past couple of weeks:&lt;/p&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://blog.kie.org/2022/04/kogito-1-20-0-released.html"&gt;Kogito 1.20.0&lt;/a&gt; - Updates including tooling, images, operator, and the CLI.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.keycloak.org/2022/04/keycloak-1800-released"&gt;Keycloak 18.0.0&lt;/a&gt; - A new admin console preview, new Operator preview, client secret rotation, session limits per user, etc. Lots of great new features and additions!&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://resteasy.dev/2022/04/19/resteasy-releases/"&gt;RESTEasy 6.1.0.Beta1&lt;/a&gt; - First release to implement Jakarta RESTful Web Services 3.1, updates to RESTEasy CDI allowing injection of certain types, and an &lt;code&gt;SeBootstrap&lt;/code&gt; API implementation.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.wildfly.org/news/2022/04/14/WildFly261-Final-Released/"&gt;Wildfly 26.1.Final&lt;/a&gt; - Honestly, too many things to list here, take a look at the blog post including new features, how to run on Java 17, and links to additional information.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://quarkus.io/blog/quarkus-2-8-1-final-released/"&gt;Quarkus 2.8.1.Final&lt;/a&gt; - First maintenance release of the 2.8 branch, it contains only bug fixes&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_kie_related_posts"&gt;KIE Related Posts&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;The KIE team (jBPM, Drools, Optaplanner, Kogito) has had some interesting posts the last couple of weeks:&lt;/p&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://blog.kie.org/2022/04/create-dashboards-using-yml-with-dashbuilder.html"&gt;Create Dashboards Using YML with Dashbuilder&lt;/a&gt; - Building data visualizations using only YAML and JSON datasets is possible and easy to do.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://blog.kie.org/2022/04/integrating-drools-dmn-engine-with-ibm-open-prediction-service.html"&gt;Integrating Drools DMN Engine with IBM Open Prediction Service&lt;/a&gt; - An interesting combination of two open source projects. This showcases the power of integrating predictive models and decision models.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://blog.kie.org/2022/04/defeasible-reasoning-drools-and-truth-maintenance-system.html"&gt;Defeasible Reasoning, Drools and Truth Maintenance System&lt;/a&gt; - Be sure to examine your truth statements and keep them up to date when dealing with rules that depend on criteria to remain truthful.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_quarkus_bits"&gt;Quarkus Bits&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;Quarkus always has interesting things going on, and these past weeks are no exception:&lt;/p&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://quarkus.io/blog/solving-problems-with-extensions/"&gt;Solving problems with Quarkus extensions (1/n)&lt;/a&gt; - Guillaume talks about breaking down complex problems and how to solve them using Quarkus extensions. This should be the first in a number of articles showcasing the power of Quarkus extensions.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="http://www.mastertheboss.com/soa-cloud/quarkus/how-to-manage-transactions-in-quarkus/"&gt;How to manage Transactions in Quarkus&lt;/a&gt; - Quarkus supports both declarative and programmatic transaction management. Francesco Marchioni showcases both approaches here.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/articles/2022/04/21/add-security-quarkus-application-using-red-hats-sso"&gt;Add security to a Quarkus application using Red Hat’s SSO&lt;/a&gt; - Olivier Rivat explains how to leverage Red Hat’s SSO product to add security in your Quarkus application using OpenID Connect (OICD) and how to test it in the browser and via the CLI.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_wildfly_buzzings"&gt;Wildfly Buzzings&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;Wildfly continues strong with a number of posts:&lt;/p&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.wildfly.org//news/2022/04/20/WildFly-s2i-v2-Released/"&gt;WildFly S2I new architecture is final!&lt;/a&gt; - If you’re deploying Wildfly in the cloud, take a look at new and easier ways to create your container images, and how to shrink them!&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://wildfly-security.github.io/wildfly-elytron/blog/client-default-ssl-context/"&gt;Client side default SSL context provider&lt;/a&gt; - You can now get access to a JVM wide &lt;code&gt;SSLContext&lt;/code&gt; using Elytron. Dive into the blog post for examples.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Do you need to encrypt your file system realm? Elytron has just what you need. Take a look at these two posts: &lt;a href="https://wildfly-security.github.io/wildfly-elytron/blog/filesystem-encryption/"&gt;Encrypting Filesystem realms&lt;/a&gt; and &lt;a href="https://wildfly-security.github.io/wildfly-elytron/blog/filesystem-encryption-tool/"&gt;Encrypting Pre-Existing Filesystem realms&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_getting_enough_rest"&gt;Getting enough REST&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;While it may not be one of the sexiest technologies, REST is used all over for communication and microservices. Take a look at two posts to get going if you’re new to RESTEasy: &lt;a href="http://www.mastertheboss.com/jboss-frameworks/resteasy/getting-started-with-jakarta-restful-services/"&gt;Getting started with Jakarta RESTful Services&lt;/a&gt; and &lt;a href="https://resteasy.dev/2022/04/14/resteasy-spring-6-wildfly-example/"&gt;RESTEasy Spring And RESTEasy Spring Boot EE9 Deployment With WildFly Preview&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_red_hat_summit_2022"&gt;Red Hat Summit 2022&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;Red Hat Summit 2022 is happening May 10th and 11th. It will be a hybrid event. Take a look at the &lt;a href="https://www.redhat.com/en/summit"&gt;Red Hat Summit page&lt;/a&gt; for more information. There will be great information, talks, events, and tech for everyone who attends either virtually or in person. We’re looking forward to seeing you there!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="author"&gt; &lt;pfe-avatar pfe-shape="circle" pfe-pattern="squares" pfe-src="/img/people/jason-porter.png"&gt;&lt;/pfe-avatar&gt; &lt;span&gt;Jason Porter&lt;/span&gt; &lt;/div&gt;&lt;/article&gt;</content><dc:creator>Jason Porter</dc:creator></entry><entry><title type="html">Create dashboards using YML with Dashbuilder</title><link rel="alternate" href="https://blog.kie.org/2022/04/create-dashboards-using-yml-with-dashbuilder.html" /><author><name>William Siqueira</name></author><id>https://blog.kie.org/2022/04/create-dashboards-using-yml-with-dashbuilder.html</id><updated>2022-04-21T21:55:00Z</updated><content type="html">Creating a dashboard using pure YML from data from any JSON document is now possible using Dashbuilder! You are not even required to install anything, just access and start your dashboard! HOW IT WAS POSSIBLE Dashbuilder was and the client was decoupled from the backend. With this change Dashbuilder could run on client only, without the requirement of a backend. On the client side can be used without the need of a backend. Naturally Dashbuilder could be used as an editor for its native dashboard definition format: JSON. However, the native format requires deep technical knowledge of how Dashbuilder works, hence multiple changes were made to make the JSON friendly to humans.  The JSON support was ready, however the YAML is easy to read and is a popular format due the use with Openshift and Kubernetes, so we decided to also support YAML, which is the conversion from JSON.  Currently we have an but a new one compatible with is in development! WHAT ABOUT DASHBUILDER AUTHORING The old Dashbuilder Authoring is in maintenance mode, which means that it continues to be released and we will fix critical issues, but new features will prioritize the YAML editor. HOW TO GET STARTED A can be found in Dashbuilder documentation. We have a few samples on the as well. The example library will grow soon, so stay tuned! The post appeared first on .</content><dc:creator>William Siqueira</dc:creator></entry><entry><title type="html">Narayana on the Cloud - Part 1</title><link rel="alternate" href="https://jbossts.blogspot.com/2022/04/narayana-on-cloud-part-1.html" /><author><name>Manuel Finelli</name></author><id>https://jbossts.blogspot.com/2022/04/narayana-on-cloud-part-1.html</id><updated>2022-04-21T17:05:00Z</updated><content type="html">In the last few months, I have been working on how distributed transactions are recovered in WildFly when this Application Server (AS) is deployed in Kubernetes. This blog post is a reflection on how Narayana performs on the cloud and the features it is still missing for it to evolve into a native cloud transaction suite. SOME (VERY BRIEF) CONTEXT Narayana started its journey more than 30 years ago! ArjunaCore was developed in the late 1980s. Even though the theoretical concept of cloud computing was introduced by John McCarthy in 1961 [1][2], at the time of ArjunaCore’s development it was still considered only as a theoretical possibility. However, in the past two decades, the implementation of cloud computing has increased exponentially, dramatically changing the world of technology. As a consequence, Narayana (and its ArjunaCore) needs to step up its game to become a cloud native transaction suite that can be used in different cloud environments. This is an ongoing conversation the Narayana team has started a long time ago (for a detailed summary of Narayana's Cloud Strategy see [3]). Narayana was introduced to the cloud through WildFly (note 1) on Kubernetes (K8s). In my recent experience, I worked on WildFly and its K8s operator [4] and I think that the integration between Narayana and WildFly works very smoothly on K8s [5]. On the other hand, when the pod hosting WildFly needs to scale down, the ephemeral nature of K8s does not get along with Narayana very well. In fact, ArjunaCore/Narayana needs to have a stable ground to perform its magic (within or without WildFly). In particular, Narayana needs to have: * A stable and durable Object Store where objects’ states are held * A stable node identifier to uniquely mark transactions (which are initialised by the Transaction Manager (TM) with the same node identifier) and ensure that the Recovery Manager will only recover those transactions * A stable communication channel to allow participants of transactions to communicate with the TM In all points above, “stable” indicates the ability to survive whatever happens to the host where Narayana is running (e.g., crashes). On the other hand, K8s is an ephemeral environment where pods do not need a stable storage and/or particular configurations that survive over multiple reboots. To overcome this “incompatibility”, K8s provides StatefulSet [6] through which applications can leverage a stable realm. Particularly in relation to Narayana, the employment of StatefulSet and the addition of a transaction recovery module to the WildFly K8s Operator [7] enables this AS to fully support transactions on K8s. Unfortunately, this solution is tailor-made for K8s and it cannot be easily ported in other cloud environments. Our target, though, is to evolve Narayana to become a cloud transaction suite, which means that Narayana should also support other cloud computing infrastructures. OUR TAKE ON THIS The Naryana team thoroughly discussed the above limitations that prevent Narayana from becoming a native cloud application. A brief summary is presented here: * A stable and durable Object Store where objects’ states are held Narayana is able to use different kinds of object stores; in particular, it is possible to use a (SQL) database to create the object store [8]. RDBMS databases are widely available on cloud environments: these solutions already cover our stability needs providing a reliable storage solution that supports replications and that is able to scale up on demand. Moreover, using a “centralised” RDBMS database would easen the management of multiple Narayana instances, which can be connected to the same database. This might also become incredibly useful in the future when it comes to evolving Narayana to work with multiple instances behind a load balancer (i.e. in case of replication)  * A stable communication channel to allow participants of transactions to communicate with the TM Most cloud providers (and platforms) already offer two options to tackle this problem: a stable IP address and a DNS. Although both methods still need some tweaking for each cloud provider, these solutions should provide a stable endpoint to communicate with Narayana’s TM over multiple reboots  * A stable node identifier to uniquely mark transactions (which are initialised by the Transaction Manager (TM) with the same node identifier) and ensure that the Recovery Manager will only recover those transactions This is the actual sticky point this blog post is about. Although it seems straightforward to assign a unique node identifier to the TM, it is indeed the first real logic challenge to solve on the path to turn Narayana in a cloud transaction manager We discussed different possible solutions to this last point but we are still trying to figure out how to address this issue. The main problem is that Narayana needs stable storage to save the node identifier and reload it after a reboot. As already said, cloud environments do not provide this option very easily as their ephemeral nature is more inclined to a stateless approach. Our first idea to solve this problem was, “why do we not store the node identifier in the object store? Narayana still needs a stable object store (and this constraint cannot be dropped) and RDBMS databases on the cloud already provide a base to start from”. The node identifier is a property of the transaction manager that gets initialised when Narayana/ArjunaCore starts (together with all the other properties). As a consequence, it is not possible to save the node identifier in the object store as the preferences for the object store are also loaded during the same initialisation process! In other words, if the node identifier is stored in the object store, how can Narayana/ArjunaCore know where the object store is without loading all properties? Which came first: the chicken or the egg? Nevertheless, introducing an order when properties are loaded might help in this regard (i.e. we force the egg to exist before the chicken). Nevertheless, there is still a problem: what happens if the object store is shared between different instances of Narayana/ArjunaCore? For example, it might be very likely that a Narayana administrator configures multiple Narayana instances to create their object stores in the same database. In this case, every Narayana instance would need a unique identifier to tell which node identifier in the object store is its own. Recursive problems are fun :-) Even if we solve all these problems, the assignment of the node identifier should not be possible outside of Narayana (e.g. using system properties) and it should become an exclusive (internal) operation of Narayana. Fortunately, this is easier than solving our previous “chicken and egg” problem as there are solutions to generate a unique distributed identifier locally [9]. As things stand, we should find an alternative solution to port the node identifier to the cloud. Looking at this problem from a different point of view, I wonder if there are more recent solutions to replace and/or remove the node identifier from Narayana. With this in mind, the first question I ask myself is “Why do we need a node identifier?”. Behind the hood, Narayana uses a recovery manager to try to recover transactions that have not completed their lifecycle. This comes with a caveat though: it is essential that two different recovery managers do not try to recover the same in-doubt transaction at the same time. That is where the node identifier comes in handy! In fact, thanks to the unique node identifier (that gets embedded in every global transaction identifier), the recovery manager can recognise if it is responsible for the recovery of an in-doubt transaction stored in a remote resource (note 2). This concept is best illustrated by an example. Let’s consider two different Narayana instances that initiate two different transactions that enlist the same resource. In this scenario, both transaction managers store a record in the shared resource. Let’s assume that the first Narayana instance starts the transaction before the second instance. While the first transaction gets to the point where it has sent prepare() to its enlisted resources, it is possible that the recovery manager of the second Narayana instance queries the shared resource for in-doubt records. If Naryana’s recovery manager was not forced to recover only transactions initiated by the same Narayana instance’s TM, this hypothetical scenario would have ended with an error: the recovery manager of the second Narayana instance would have rolled back the transaction initiated by the first Narayana instance, assuming that it was one of its own in-doubt transaction! Cloud environments are encouraging (all of) us to come up with an innovative solution to reduce the footprint of Narayana/ArjunaCore. In particular, the node identifier is the challenge we are currently facing and the first real step to push Narayana onto the cloud. I will share any updates the Narayana team comes up with…and in the meantime, feel free to reach out to the team through our public channels (for example Gitter or our Google group narayana-users) to propose your ideas or discuss with us your take on this fundamental issue. NOTE 1. WildFly supports transactions thanks to the integration with Narayana 2. It is possible to tell the Recovery Manager that it will be responsible for the recovery of in-doubt transactions initiated by different transaction managers (which are identified with different node identifiers). The only caveat here is that two Recovery Managers should not recover the same in-doubt transaction at the same time. To assign the responsibility of multiple node identifiers to the same Recovery Manager, the property xaRecoveryNodes [10] in Narayana’s JTAEnvironmentBean should be used. BIBLIOGRAPHY [1] J. Surbiryala and C. Rong, "Cloud Computing: History and Overview," 2019 IEEE Cloud Summit, 2019, pp. 1-7, doi: 10.1109/CloudSummit47114.2019.00007. [2] Garfinkel, Simson L. and Harold Abelson. “Architects of the Information Society: 35 Years of the Laboratory for Computer Science at Mit.” (1999). [3] https://jbossts.blogspot.com/2022/03/narayana-community-priorities.html [4] https://github.com/wildfly/wildfly-operator [5] https://issues.redhat.com/browse/EAP7-1394 [6] https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/ [7] https://github.com/wildfly/wildfly-operator/ [8] https://www.narayana.io/docs/project/index.html#d0e459 [9] https://groups.google.com/g/narayana-users/c/ttSff9HvXdA [10] https://www.narayana.io//docs/product/index.html#d0e1032</content><dc:creator>Manuel Finelli</dc:creator></entry><entry><title type="html">Getting started with Jakarta RESTful Services</title><link rel="alternate" href="http://www.mastertheboss.com/jboss-frameworks/resteasy/getting-started-with-jakarta-restful-services/" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/jboss-frameworks/resteasy/getting-started-with-jakarta-restful-services/</id><updated>2022-04-21T16:44:56Z</updated><content type="html">The latest release of RESTEasy (6.1.0) provides an overview of what’s coming with Jakarta RESTful Web Services 3.1. which will be a core component of Jakarta EE 10. Let’s review through this article the upcoming features using RESTEasy (6.1.0) implementation. What’s new in Jakarta RESTful Web Services 3.1 There is currently a list of proposal ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title>Add security to a Quarkus application using Red Hat's SSO</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/04/21/add-security-quarkus-application-using-red-hats-sso" /><author><name>Olivier Rivat</name></author><id>7436626c-5883-4085-b1db-1dd801c7eca5</id><updated>2022-04-21T07:00:00Z</updated><published>2022-04-21T07:00:00Z</published><summary type="html">&lt;p&gt;&lt;a href="https://developers.redhat.com/products/quarkus/overview"&gt;Quarkus&lt;/a&gt; applications, like many other &lt;a href="https://developers.redhat.com/topics/enterprise-java"&gt;Java&lt;/a&gt; applications in use today, run on the network and require user authentication. If you are developing a Quarkus application that will run on a &lt;a href="https://developers.redhat.com/openshift"&gt;Red Hat OpenShift&lt;/a&gt; or &lt;a href="https://developers.redhat.com/products/rhel"&gt;Red Hat Enterprise Linux&lt;/a&gt; platform, you can add security quickly and easily through &lt;a href="https://access.redhat.com/products/red-hat-single-sign-on"&gt;Red Hat's single sign-on&lt;/a&gt; (SSO) technology. This article takes you through the steps, with an example Quarkus application deployed on Red Hat Enterprise Linux.&lt;/p&gt; &lt;h2&gt;Create a Quarkus project&lt;/h2&gt; &lt;p&gt;The procedure in this article uses a simple example application from the &lt;a href="https://quarkus.io/guides/getting-started"&gt;Quarkus guide&lt;/a&gt;. You can install the example using Maven:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ mvn io.quarkus.platform:quarkus-maven-plugin:2.7.1.Final:create \ -DprojectGroupId=org.acme \ -DprojectArtifactId=getting-started \ -Dextensions="resteasy"&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This application is deployed in the &lt;code&gt;getting-started&lt;/code&gt; directory, so go to that directory:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ cd getting-started&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Start the application in dev mode:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ mvn quarkus:dev&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;You can make sure that the application is installed by visiting its URL &lt;code&gt;http://localhost:8080/hello&lt;/code&gt; on your local system, either in a browser or from the command line:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ curl -w "\n" http://localhost:8080/hello Hello RESTEasy&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Prepare Red Hat's SSO&lt;/h2&gt; &lt;p&gt;As you saw in that listing, when you visit this URL, the sample Quarkus application will display a message that says "Hello RESTEasy". In the rest of this article, you'll learn how to secure this Quarkus URL using Red Hat's single sign-on technology. To do so, you'll need to register the Quarkus application as a Red Hat single sign-on client.&lt;/p&gt; &lt;p&gt;With single sign-on in place, any browser call to the Quarkus application's URL &lt;code&gt;http://localhost:8080/hello&lt;/code&gt; will redirect the user to the single sign-on authentication server at &lt;code&gt;http://localhost:8180/auth&lt;/code&gt;. Only after the user authenticates will they be redirected back to the greeting from the Quarkus application.&lt;/p&gt; &lt;p&gt;As you can tell from the URLs, the Quarkus application communicates over the default web port 8080, and Red Hat's SSO therefore has to be started on a different port. The following command starts the SSO on port 8180:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ sh standalone.sh -Djboss.socket.binding.port-offset=100&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Go to the console for Red Hat's SSO at &lt;code&gt;http://localhost:8180/auth/admin/&lt;/code&gt;. Create a realm called &lt;code&gt;quarkus&lt;/code&gt; and add a user named &lt;code&gt;user1&lt;/code&gt; to this realm (Figure 1).&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/user_2.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/user_2.png?itok=KYyG5sWA" width="947" height="610" alt="You can configure a realm and a user in Red Hat's SSO console." loading="lazy" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1. You can configure a realm and a user in Red Hat's SSO console. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 1: You can configure a realm and a user in Red Hat's SSO console.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Configure the Quarkus application to authenticate with Red Hat's SSO&lt;/h2&gt; &lt;p&gt;Also within the &lt;code&gt;quarkus&lt;/code&gt; realm, create a client named &lt;code&gt;hello&lt;/code&gt; (Figure 2). This corresponds to the Quarkus example application you've installed. Configure the client's access type as &lt;strong&gt;confidential.&lt;/strong&gt;&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/hello.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/hello.png?itok=7OZ7NaOi" width="1412" height="960" alt="The Hello application should be made confidential in Red Hat's SSO console." loading="lazy" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 2. The Hello application should be made confidential in Red Hat's SSO console. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 2: The Hello application should be made confidential in Red Hat's SSO console.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;This &lt;code&gt;hello&lt;/code&gt; client uses a client ID and secret for authentication. The client secret is generated by Red Hat's SSO (Figure 3), and you need to copy the secret for later use.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/secret.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/secret.png?itok=OcG7zDnj" width="1215" height="362" alt="Red Hat's SSO console generates a secret for the Hello application." loading="lazy" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 3. Red Hat's SSO console generates a secret for the Hello application. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 3: Red Hat's SSO console generates a secret for the Hello application.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Update the Quarkus application and configuration&lt;/h2&gt; &lt;p&gt;Your application communicates using &lt;a href="https://openid.net/connect/"&gt;OpenID Connect&lt;/a&gt; (OICD), so add the OIDC extension to your Quarkus project:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ ./mvnw quarkus:add-extension -Dextensions="oidc" &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Relaunch the application in debug mode:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ mvn quarkus:dev&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Then update the &lt;code&gt;application.properties&lt;/code&gt; file to integrate Red Hat's SSO. Supply the appropriate values for your instance of the application when setting the following variables:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;code&gt;quarkus.oidc.client-id&lt;/code&gt;: Client ID of the application&lt;/li&gt; &lt;li&gt;&lt;code&gt;quarkus.oidc.credentials.secret&lt;/code&gt;: Client secret of the application&lt;/li&gt; &lt;li&gt;&lt;code&gt;quarkus.oidc.auth-server-url&lt;/code&gt;: URL of the application&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;The lines related to authentication and OIDC should look like the following, though you should swap in the proper values for your application:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt;quarkus.oidc.auth-server-url=http://localhost:8180/auth/realms/quarkus quarkus.oidc.client-id=hello quarkus.oidc.credentials.secret=ec7200d9-ccb3-4335-ac72-d2ccd2aab190 quarkus.oidc.application-type=web-app quarkus.http.auth.permission.authenticated.paths=/* quarkus.http.auth.permission.authenticated.policy=authenticated&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;For more information about these properties, see the &lt;a href="https://quarkus.io/guides/security-openid-connect-web-authentication#quarkus-oidc_configuration"&gt;Quarkus configuration reference&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Any further calls to this Quarkus application will now redirect the user to Red Hat's SSO for authentication.&lt;/p&gt; &lt;h2&gt;Test the application with Red Hat's SSO&lt;/h2&gt; &lt;p&gt;Now you can visit your application's URL again and see that authentication is in place.&lt;/p&gt; &lt;h3&gt;Browser testing&lt;/h3&gt; &lt;p&gt;Browser testing invokes Red Hat's SSO standard flow, which uses an &lt;a href="https://datatracker.ietf.org/doc/html/rfc6749#section-4.1"&gt;OAuth 2.0 authorization code grant&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Just enter &lt;code&gt;http://localhost:8080/hello&lt;/code&gt; into a browser window. You should be redirected to the &lt;code&gt;quarkus&lt;/code&gt; realm in Red Hat's SSO, where you need to authenticate as &lt;code&gt;user1&lt;/code&gt;. The following credentials are used for this example:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Username: &lt;code&gt;user1&lt;/code&gt;&lt;/li&gt; &lt;li&gt;Password: &lt;code&gt;password&lt;/code&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;REST API testing&lt;/h3&gt; &lt;p&gt;When you test the application by issuing REST API queries from the command line, you invoke Red Hat's SSO direct access grant flow, which uses an &lt;a href="https://datatracker.ietf.org/doc/html/rfc6749#section-4.3"&gt;OAuth 2.0 read-only password grant&lt;/a&gt;. It delivers&lt;em&gt; &lt;/em&gt;an&lt;em&gt; access token&lt;/em&gt; and a &lt;em&gt;refresh token&lt;/em&gt; in its response to the query:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ curl -d "client_id=hello" -d client_secret=ec7200d9-ccb3-4335-ac72-d2ccd2aab190 -d "username=user1" -d "password=password" -d "grant_type=password" "http://localhost:8180/auth/realms/quarkus/protocol/openid-connect/token" | jq { "access_token": "eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJoMHhOVEV1Y3drcWdSNkd3TEkxVXVHcExGLVBjTU1sWnROdDBabGYyM2hnIn0.eyJleHAiOjE2NDcyNjQ5MjIsImlhdCI6MTY0NzI2NDYyMiwianRpIjoiMWQ3MmE2NDYtNzc2NS00MWJkLWFmZmQtZjNhMmEyZGM1MTM0IiwiaXNzIjoiaHR0cDovL2xvY2FsaG9zdDo4MTgwL2F1dGgvcmVhbG1zL3F1YXJrdXMiLCJhdWQiOiJhY2NvdW50Iiwic3ViIjoiYzkwN2M2N2UtZDc2Ny00ZGRlLWI5N2UtOWVhMmY1NTYzOGVlIiwidHlwIjoiQmVhcmVyIiwiYXpwIjoiaGVsbG8iLCJzZXNzaW9uX3N0YXRlIjoiM2NlMWM0YWEtMDE5Yy00MGExLWFkMDEtYWJjYzJmYmNhZTEwIiwiYWNyIjoiMSIsImFsbG93ZWQtb3JpZ2lucyI6WyJodHRwOi8vbG9jYWxob3N0OjgwODAiXSwicmVhbG1fYWNjZXNzIjp7InJvbGVzIjpbIm9mZmxpbmVfYWNjZXNzIiwiZGVmYXVsdC1yb2xlcy1xdWFya3VzIiwidW1hX2F1dGhvcml6YXRpb24iXX0sInJlc291cmNlX2FjY2VzcyI6eyJhY2NvdW50Ijp7InJvbGVzIjpbIm1hbmFnZS1hY2NvdW50IiwibWFuYWdlLWFjY291bnQtbGlua3MiLCJ2aWV3LXByb2ZpbGUiXX19LCJzY29wZSI6ImVtYWlsIHByb2ZpbGUiLCJzaWQiOiIzY2UxYzRhYS0wMTljLTQwYTEtYWQwMS1hYmNjMmZiY2FlMTAiLCJlbWFpbF92ZXJpZmllZCI6ZmFsc2UsInByZWZlcnJlZF91c2VybmFtZSI6InVzZXIxIn0.SN8xZevRdFba6oB4fWIrde4I75U5osTZsvhw6bZjGnwer-bVcTNEtlokNEk3Ro5LsqtPEQ7by7ZdCKwnWHuPPC0EGqS8p4Kskfh20DdTx1NzboabKujv3d7JnkoEg3QPNsIzhHz3Hx095mZTf9KwAXQrtUwKk50xCtfQCccWLV5RMzuVlQ0z1s4wS0t_9PF-G_aNwK-evpHTuHPUrTV_A71bLcaaRDrUSgG9ux1-yJNGa_pHoT3-au0lOMix3d6DRUesFzLkESrIK6_OIvqk4bFToQCQDq48YvZKZlOnAwDWIv5KJ8m3X3TnmUmXa_YiUugQlYmZC0Jk49tIU0_SPQ", "expires_in": 300, "refresh_expires_in": 1800, "refresh_token": "eyJhbGciOiJIUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICI0NmViYTE1Ni02ZDgyLTQ1NTMtOWI3Zi1kNjM2Yjk3MjFhYjEifQ.eyJleHAiOjE2NDcyNjY0MjIsImlhdCI6MTY0NzI2NDYyMiwianRpIjoiODY3M2RhNTUtYmNjYi00YjczLWEzYzctZjQ1ZWQyOTkyZTU4IiwiaXNzIjoiaHR0cDovL2xvY2FsaG9zdDo4MTgwL2F1dGgvcmVhbG1zL3F1YXJrdXMiLCJhdWQiOiJodHRwOi8vbG9jYWxob3N0OjgxODAvYXV0aC9yZWFsbXMvcXVhcmt1cyIsInN1YiI6ImM5MDdjNjdlLWQ3NjctNGRkZS1iOTdlLTllYTJmNTU2MzhlZSIsInR5cCI6IlJlZnJlc2giLCJhenAiOiJoZWxsbyIsInNlc3Npb25fc3RhdGUiOiIzY2UxYzRhYS0wMTljLTQwYTEtYWQwMS1hYmNjMmZiY2FlMTAiLCJzY29wZSI6ImVtYWlsIHByb2ZpbGUiLCJzaWQiOiIzY2UxYzRhYS0wMTljLTQwYTEtYWQwMS1hYmNjMmZiY2FlMTAifQ.lrrq_toV92cf2mzJoWRrUs7MteCXgF_MFgdNlJ3o82A", "token_type": "Bearer", "not-before-policy": 0, "session_state": "3ce1c4aa-019c-40a1-ad01-abcc2fbcae10", "scope": "email profile" }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;It is also possible to display the details of the access token:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ access_token=`curl -d "client_id=hello" -d client_secret=ec7200d9-ccb3-4335-ac72-d2ccd2aab190 -d "username=user1" -d "password=password" -d "grant_type=password" "http://localhost:8180/auth/realms/quarkus/protocol/openid-connect/token" | jq -r .access_token` echo $access_token | cut -d"." -f2 | base64 -d | jq base64: invalid input { "exp": 1647265083, "iat": 1647264783, "jti": "073295d8-1829-4f01-a58f-0d6497782ddd", "iss": "http://localhost:8180/auth/realms/quarkus", "aud": "account", "sub": "c907c67e-d767-4dde-b97e-9ea2f55638ee", "typ": "Bearer", "azp": "hello", "session_state": "4b15f101-efce-4c8e-8206-beba5e06e7fc", "acr": "1", "allowed-origins": [ "http://localhost:8080" ], "realm_access": { "roles": [ "offline_access", "default-roles-quarkus", "uma_authorization" ] }, "resource_access": { "account": { "roles": [ "manage-account", "manage-account-links", "view-profile" ] } }, "scope": "email profile", "sid": "4b15f101-efce-4c8e-8206-beba5e06e7fc", "email_verified": false, "preferred_username": "user1" }&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;This simple example has shown how easy it is to add security to a Quarkus application with Red Hat's SSO. Quarkus applications can be secured with Red Hat's SSO just as enterprise Java applications can.&lt;/p&gt; &lt;p&gt;For further information about Quarkus application security, please read the &lt;a href="https://quarkus.io/guides/#security"&gt;security sections of the Quarkus guide&lt;/a&gt;. To learn more about using Red Hat's single sign-on technology, check out my earlier articles on Red Hat Developer:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2021/05/19/deploy-red-hats-single-sign-technology-red-hat-openshift-using-templates"&gt;Deploy Red Hat's single sign-on technology on Red Hat OpenShift using templates&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2021/03/25/integrate-red-hats-single-sign-on-technology-7-4-with-red-hat-openshift"&gt;Deploy Red Hat’s single sign-on technology 7.4 with Red Hat OpenShift&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2021/02/19/x-509-user-certificate-authentication-with-red-hats-single-sign-on-technology"&gt;X.509 user certificate authentication with Red Hat's single sign-on technology&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/04/21/add-security-quarkus-application-using-red-hats-sso" title="Add security to a Quarkus application using Red Hat's SSO"&gt;Add security to a Quarkus application using Red Hat's SSO&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Olivier Rivat</dc:creator><dc:date>2022-04-21T07:00:00Z</dc:date></entry><entry><title>Deploy Keycloak single sign-on with Ansible</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/04/20/deploy-keycloak-single-sign-ansible" /><author><name>Romain Pelisse</name></author><id>7f17be01-c88d-45b6-be02-71b1f3b07f0b</id><updated>2022-04-20T07:00:00Z</updated><published>2022-04-20T07:00:00Z</published><summary type="html">&lt;p&gt;This article is the fourth installment in our series on &lt;a href="https://developers.redhat.com/products/ansible/overview"&gt;Ansible&lt;/a&gt; for middleware. In this article, you'll use Ansible to simplify and automate the installation of &lt;a href="https://www.redhat.com/en/blog/getting-started-keycloak-single-sign-operator"&gt;Keycloak&lt;/a&gt;, a popular &lt;a href="https://developers.redhat.com/topics/open-source"&gt;open source&lt;/a&gt; tool to implement single sign-on for Web applications. The previous articles in this series are:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2021/08/30/automate-red-hat-jboss-web-server-deployments-ansible"&gt;Automate Red Hat JBoss Web Server deployments with Ansible&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/02/08/automate-and-deploy-jboss-eap-cluster-ansible"&gt;Automate and deploy a JBoss EAP cluster with Ansible&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/03/21/deploy-infinispan-automatically-ansible"&gt;Deploy Infinispan automatically with Ansible&lt;/a&gt;&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;The tutorial in this article builds on an Ansible Collection named &lt;a href="https://galaxy.ansible.com/middleware_automation/keycloak"&gt;middleware_automation.keycloak&lt;/a&gt;, which has been specifically designed for this endeavor.&lt;/p&gt; &lt;h2&gt;Prerequisites&lt;/h2&gt; &lt;p&gt;To make use of this tutorial, you need a &lt;a href="https://developers.redhat.com/products/rhel"&gt;Red Hat Enterprise Linux&lt;/a&gt; or &lt;a href="https://getfedora.org"&gt;Fedora&lt;/a&gt; system, along with version 2.9 or higher of Ansible (preferably the latest version).&lt;/p&gt; &lt;h2&gt;Install the collection&lt;/h2&gt; &lt;p&gt;The very first step, of course, is to install the collection itself, so that Ansible can use its content inside playbooks:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ ansible-galaxy collection install middleware_automation.keycloak Starting galaxy collection install process Process install dependency map Starting collection install process Downloading https://galaxy.ansible.com/download/middleware_automation-keycloak-1.0.0.tar.gz to /root/.ansible/tmp/ansible-local-24nzydu97b/tmpaql0qbek/middleware_automation-keycloak-1.0.0-8yma1_vi Installing 'middleware_automation.keycloak:1.0.0' to '/root/.ansible/collections/ansible_collections/middleware_automation/keycloak' Downloading https://galaxy.ansible.com/download/middleware_automation-redhat_csp_download-1.2.1.tar.gz to /root/.ansible/tmp/ansible-local-24nzydu97b/tmpaql0qbek/middleware_automation-redhat_csp_download-1.2.1-4po4eg4w middleware_automation.keycloak:1.0.0 was installed successfully Installing 'middleware_automation.redhat_csp_download:1.2.1' to '/root/.ansible/collections/ansible_collections/middleware_automation/redhat_csp_download' Downloading https://galaxy.ansible.com/download/middleware_automation-wildfly-1.0.1.tar.gz to /root/.ansible/tmp/ansible-local-24nzydu97b/tmpaql0qbek/middleware_automation-wildfly-1.0.1-ayf0n_nq middleware_automation.redhat_csp_download:1.2.1 was installed successfully Installing 'middleware_automation.wildfly:1.0.1' to '/root/.ansible/collections/ansible_collections/middleware_automation/wildfly' middleware_automation.wildfly:1.0.1 was installed successfully&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The collection has the following dependencies:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;code&gt;middleware_automation.redhat_csp&lt;/code&gt;: This collection allows Ansible to connect to the Red Hat Customer Portal to download &lt;a href="https://access.redhat.com/products/red-hat-single-sign-on"&gt;Red Hat's single sign-on technology&lt;/a&gt;, which is a productized and supported version of Keycloak. We won't use this feature in this article.&lt;/li&gt; &lt;li&gt;&lt;code&gt;middleware_automation.wildfly&lt;/code&gt;: Keycloak runs on top of the &lt;a href="https://www.wildfly.org"&gt;Wildfly&lt;/a&gt; application server, including &lt;a href="https://developers.redhat.com/products/eap/overview"&gt;Red Hat JBoss Enterprise Application Platform&lt;/a&gt; (JBoss EAP), which is the version of Wildfly supported by Red Hat. For more details about this collection, please refer to the second article in this series, &lt;a href="https://developers.redhat.com/articles/2022/02/08/automate-and-deploy-jboss-eap-cluster-ansible"&gt;Automate and deploy a JBoss EAP Cluster with Ansible&lt;/a&gt;.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;Depending on the configuration of the machine used as the Ansible controller, you might need to add some Python dependencies so that Ansible will have the libraries required to make use of the collection. Install them by running the following command:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt;# pip3 install lxml jmespath Collecting lxml Downloading lxml-4.7.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.9 MB) |████████████████████████████████| 6.9 MB 1.9 MB/s Collecting jmespath Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB) Installing collected packages: lxml, jmespath Successfully installed jmespath-0.10.0 lxml-4.7.1&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Before going further, you should check to make sure that the collection has been successfully installed. To do so, run the following command from Ansible Galaxy that will list all the installed collections.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note&lt;/strong&gt;: This collection list feature is available in Ansible Galaxy 2.12, but not 2.9.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;# ansible-galaxy collection list # /root/.ansible/collections/ansible_collections Collection Version ----------------------------------------- ------- middleware_automation.keycloak 1.0.1 middleware_automation.redhat_csp_download 1.2.1 middleware_automation.wildfly 1.0.2 &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Now that the collection and its dependencies are installed, you can use it in an automation:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt;--- - name: Playbook for keycloak Hosts hosts: keycloak collections: - middleware_automation.keycloak tasks:&lt;/code&gt;&lt;/pre&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note&lt;/strong&gt;: In order for this playbook to perform the installation outlined here, Ansible must have sudo or root privileges on the target hosts.&lt;/p&gt; &lt;h2&gt;Install Keycloak with Ansible&lt;/h2&gt; &lt;p&gt;Thanks to the dedicated collection you just installed, automating the installation and configuration of Keycloak is easy. However, before you implement this inside your playbook, we should recap what we mean here by &lt;em&gt;installing Keycloak.&lt;/em&gt; Indeed, this task encompasses quite a few operations that are performed on the target system:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Creating appropriate operating system user and group accounts (the name is &lt;code&gt;keycloak&lt;/code&gt; for both)&lt;/li&gt; &lt;li&gt;Downloading the installation archive from the Keycloak website&lt;/li&gt; &lt;li&gt;Unarchiving the content while ensuring that all the files are associated with the appropriate user and groups along with the correct privileges&lt;/li&gt; &lt;li&gt;Ensuring that the required version of the Java Virtual Machine (JVM) is installed&lt;/li&gt; &lt;li&gt;Integrating the software into the host service management system (in our case, the Linux &lt;a href="https://www.linux.com/training-tutorials/understanding-and-using-systemd/"&gt;systemd&lt;/a&gt; daemon).&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;All of this is achieved and is fully automated by the following short playbook:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt; - name: Playbook for Keycloak Hosts hosts: keycloak collections: - middleware_automation.keycloak tasks: - name: Include keycloak role ansible.builtin.include_role: name: middleware_automation.keycloak.keycloak vars: keycloak_admin_password: "changeme"&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The playbook begins by defining a variable for the Keycloak server administrative user. Note that, because this variable is a password, it should really be secured using &lt;a href="https://docs.ansible.com/ansible/latest/user_guide/vault.html"&gt;Ansible Vault&lt;/a&gt; or some other secrets management system. However, that task is beyond the scope of this article.&lt;/p&gt; &lt;p&gt;The configuration then adds the Ansible collection for Keycloak to the list used by the playbook and adds the associated &lt;code&gt;middleware_automation.keycloak.keycloak&lt;/code&gt; role to the list of roles that the playbook uses.&lt;/p&gt; &lt;p&gt;Run this playbook as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;# ansible-playbook -i inventory playbook.yml PLAY [Playbook for Keycloak Hosts] *************************************************************************************************************************** TASK [Gathering Facts] *************************************************************************************************************************************** ok: [localhost] TASK [middleware_automation.keycloak.keycloak : Validating arguments against arg spec 'main'] **************************************************************** ok: [localhost] TASK [middleware_automation.keycloak.keycloak : Check prerequisites] ***************************************************************************************** included: /root/.ansible/collections/ansible_collections/middleware_automation/keycloak/roles/keycloak/tasks/prereqs.yml for localhost TASK [middleware_automation.keycloak.keycloak : Validate configuration] … TASK [middleware_automation.keycloak.keycloak : Create keycloak admin user] ********************************************************************************** changed: [localhost] TASK [middleware_automation.keycloak.keycloak : Restart keycloak] ******************************************************************************************** included: /root/.ansible/collections/ansible_collections/middleware_automation/keycloak/roles/keycloak/tasks/restart_keycloak.yml for localhost TASK [middleware_automation.keycloak.keycloak : Restart and enable keycloak service] ************************************************************************ changed: [localhost] TASK [middleware_automation.keycloak.keycloak : Wait until keycloak becomes active http://localhost:9990/health] ********************************************* FAILED - RETRYING: [localhost]: Wait until keycloak becomes active http://localhost:9990/health (25 retries left). ok: [localhost] PLAY RECAP *************************************************************************************************************************************************** localhost : ok=44 changed=2 unreachable=0 failed=0 skipped=14 rescued=1 ignored=0 &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;More than forty tasks from the included role have been executed, taking care of all the requirements mentioned earlier: user and group creation, the software download, installing the required JVM, etc.&lt;/p&gt; &lt;h2&gt;Check for successful installation&lt;/h2&gt; &lt;p&gt;Once the playbook finishes its execution, you can confirm that Keycloak is now running as a service by verifying the status of the service:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;# ● keycloak.service - Keycloak Server Loaded: loaded (/etc/systemd/system/keycloak.service; enabled; vendor preset: disabled) Active: active (running) since Mon 2022-03-21 08:06:08 UTC; 3min 36s ago Process: 1553 ExecStop=/opt/keycloak/keycloak-service.sh stop (code=exited, status=0/SUCCESS) Process: 1571 ExecStart=/opt/keycloak/keycloak-service.sh start (code=exited, status=0/SUCCESS) Main PID: 1636 (java) Tasks: 79 (limit: 1638) Memory: 1012.8M CGroup: /system.slice/keycloak.service ├─1574 /bin/sh /opt/keycloak/keycloak-15.0.2/bin/standalone.sh -Djboss.bind.address=0.0.0.0 -Djboss.http.port=8080 -Djboss.https.port=8443 -Djboss.management.http.port=9990 -Djboss.management.https.port=9993 -Djboss.node.name=&gt; └─1636 java -D[Standalone] -server -Xms1024m -Xmx2048m -Dorg.jboss.boot.log.file=/opt/keycloak/keycloak-15.0.2/standalone/log/server.log -Dlogging.configuration=file:/opt/keycloak/keycloak-15.0.2/standalone/configuration/loggi&gt; Mar 21 08:06:17 7efa2c53bfe8 keycloak-service.sh[1571]: 08:06:17,566 INFO [org.jboss.resteasy.resteasy_jaxrs.i18n] (ServerService Thread Pool -- 65) RESTEASY002220: Adding singleton resource org.keycloak.services.resources.RobotsResourc&gt; Mar 21 08:06:17 7efa2c53bfe8 keycloak-service.sh[1571]: 08:06:17,567 INFO [org.jboss.resteasy.resteasy_jaxrs.i18n] (ServerService Thread Pool -- 65) RESTEASY002210: Adding provider singleton org.keycloak.services.util.ObjectMapperResolv&gt; Mar 21 08:06:17 7efa2c53bfe8 keycloak-service.sh[1571]: 08:06:17,567 INFO [org.jboss.resteasy.resteasy_jaxrs.i18n] (ServerService Thread Pool -- 65) RESTEASY002220: Adding singleton resource org.keycloak.services.resources.WelcomeResour&gt; Mar 21 08:06:17 7efa2c53bfe8 keycloak-service.sh[1571]: 08:06:17,567 INFO [org.jboss.resteasy.resteasy_jaxrs.i18n] (ServerService Thread Pool -- 65) RESTEASY002220: Adding singleton resource org.keycloak.services.resources.RealmsResourc&gt; Mar 21 08:06:17 7efa2c53bfe8 keycloak-service.sh[1571]: 08:06:17,650 INFO [org.wildfly.extension.undertow] (ServerService Thread Pool -- 65) WFLYUT0021: Registered web context: '/auth' for server 'default-server' Mar 21 08:06:17 7efa2c53bfe8 keycloak-service.sh[1571]: 08:06:17,728 INFO [org.jboss.as.server] (ServerService Thread Pool -- 43) WFLYSRV0010: Deployed "keycloak-server.war" (runtime-name : "keycloak-server.war") Mar 21 08:06:17 7efa2c53bfe8 keycloak-service.sh[1571]: 08:06:17,764 INFO [org.jboss.as.server] (Controller Boot Thread) WFLYSRV0212: Resuming server Mar 21 08:06:17 7efa2c53bfe8 keycloak-service.sh[1571]: 08:06:17,766 INFO [org.jboss.as] (Controller Boot Thread) WFLYSRV0025: Keycloak 15.0.2 (WildFly Core 15.0.1.Final) started in 9864ms - Started 596 of 873 services (584 services are&gt; Mar 21 08:06:17 7efa2c53bfe8 keycloak-service.sh[1571]: 08:06:17,768 INFO [org.jboss.as] (Controller Boot Thread) WFLYSRV0060: Http management interface listening on http://127.0.0.1:9990/management Mar 21 08:06:17 7efa2c53bfe8 keycloak-service.sh[1571]: 08:06:17,768 INFO [org.jboss.as] (Controller Boot Thread) WFLYSRV0051: Admin console listening on http://127.0.0.1:9990/code&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Note that the playbook execution itself verifies that the service is running and that the Keycloak server itself is also available:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;… TASK [middleware_automation.keycloak.keycloak : Restart and enable keycloak service] ************************************************** changed: [localhost] TASK [middleware_automation.keycloak.keycloak : Wait until keycloak becomes active http://localhost:9990/health] *********************** ok: [localhost]&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;However, for the sake of being thorough, you should double-check that the Keycloak port is indeed accessible:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;# curl -I http://localhost:9990/health HTTP/1.1 200 OK Connection: keep-alive Content-Type: application/json Content-Length: 283 Date: Fri, 18 Mar 2022 09:38:00 GMT&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;If you navigate to &lt;a href="http://localhost:8080/"&gt;http://localhost:8080/&lt;/a&gt;, you will have access to your fully ready installation of Keycloak (Figure 1).&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/key_0.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/key_0.png?itok=jT0wsq_e" width="1440" height="635" alt="The Keycloak administrative site is running on the local computer." loading="lazy" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1. The Keycloak administrative site is running on the local computer. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 1: The Keycloak administrative site should be running on your local computer.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;To summarize, at the end of this playbook execution, you'll have a running &lt;code&gt;systemd&lt;/code&gt; service managing an instance of Keycloak.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;By using Ansible and the Ansible Collection for Keycloak as outlined in this article, you can fully automate the deployment of a single sign-on server. In this article, Ansible has performed all the heavy lifting: downloading software, preparing the operating system (user, group, firewall), deploying the binary files and the configuration, setting up the service (&lt;code&gt;systemd&lt;/code&gt;), and even preparing the required administrative account. The Ansible Collection for Keycloak allows you to streamline the installation and configuration of Keycloak, thus enabling you to scale deployments as necessary and ensure repeatability across them all.&lt;/p&gt; &lt;p&gt;In an upcoming article, we'll discuss how to further automate Keycloak's single sign-on service by creating realms and their members using Ansible.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/04/20/deploy-keycloak-single-sign-ansible" title="Deploy Keycloak single sign-on with Ansible"&gt;Deploy Keycloak single sign-on with Ansible&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Romain Pelisse</dc:creator><dc:date>2022-04-20T07:00:00Z</dc:date></entry><entry><title type="html">WildFly S2I new architecture is final!</title><link rel="alternate" href="https://wildfly.org//news/2022/04/20/WildFly-s2i-v2-Released/" /><author><name>Jean-François Denise</name></author><id>https://wildfly.org//news/2022/04/20/WildFly-s2i-v2-Released/</id><updated>2022-04-20T00:00:00Z</updated><content type="html">NEW WILDFLY ON THE CLOUD ARCHITECTURE We have released the new components that make for a completely redesigned WildFly cloud experience. This redesign allows for more flexibility, simpler workflows and smaller application images. Our new cloud architecture is composed of 5 main components: * New WildFly Source-to-Image (S2I) builder images ( and ) * New WildFly runtime images ( and ) * New * New * New The new S2I workfow can be summarized as: * Configure the WildFly Maven plugin to deploy your application in the WildFly server of your choice, finely tuned according to your needs ()! * Make your application sources available in a GIT repository (). * Define a Helm Chart for WildFly yaml file (). * Install your Helm file into OpenShift (). You are done! To get you familiar with the various components you can directly jump to these . They will drive you through various use-cases from source to deployment on OpenShift (for immediate access to an OpenShift cluster, you can use ). LEGACY WILDFLY S2I AND RUNTIME CENTOS7 IMAGES We have released the legacy images for WildFly 26.1.0.Final in . We are not planning to release any centos7 images starting WildFly 27. Note When using the legacy S2I images for WildFly, you must stay on the 1.x version of the Helm Chart for WildFly: helm install my-legacy-app -f helm.yaml wildfly/wildfly --version ^1.x NEW WILDFLY S2I AND RUNTIME IMAGES We have released our new based images: * S2I builder image. * S2I builder image. * runtime image. * runtime image. S2I builder images and runtime images, although directly usable from docker build (an example of docker image built from a WildFly runtime image can be found ) or tooling, are best used when using Helm Chart for WildFly. Helm Chart create smart chained builds in order to output lightweight application images running on the runtime of your choice (JDK11 or JDK17). Detailed documentation can be found . UNIVERSAL BASE IMAGE 8 MINIMAL Our new images are based on . The UBI8 image has been designed and engineered to be the base layer for containerized applications. The Minimal flavor is a stripped down image. RELATIONSHIP WITH THE OPENJDK S2I IMAGES Our new images are sharing the Java VM configuration with the . This has multiple benefits: * JDK alignement. Benefit from latest updates. * JVM configuration alignment. Benefit from the same automatic tuning and configuration of Java VM. In the end you are getting an homogeneous user experience whatever the kind of WildFly server packaging you have chosen: WildFly Bootable JAR that runs on the openjdk images or WildFly that runs on our new images. AN S2I BUILDER IMAGE DECOUPLED FROM WILDFLY SERVER S2I builder images are generic and can be used to deploy application for any WildFly server version. Builder images have no dependency on a WildFly server release (as opposed to the legacy centos7 WildFly images that are bound to a given server version). You can even run Jakarta EE8 or Jakarta EE9-based application from these images. The and are identical applications deployed on different kind of WildFly server. Just a matter of choosing the right Galleon feature-packs to assemble the right server. RELEASE OF THE NEW IMAGES Images release cadence is now decoupled from the WildFly server release cadence. Images have their own lifecycle. New releases will be done to address fixes and new features. Released images are deployed in the For the one that love to be on the bleeding edge we are constantly deploying images under development to the . USING THE JDK 17 S2I BUILDER IMAGE Applications are built and run similarly on JDK11 and JDK17. For JDK17 just make sure to have your maven projects to use 3.3.2 version for the . This shows how to configure the Maven war plugin version. Note When using the JDK17 image, you need to set the following env variable to workaround : JAVA_OPTS_APPEND=--add-exports=jdk.naming.dns/com.sun.jndi.dns=ALL-UNNAMED MULTIARCH IMAGES PREVIEW We have released preview of Multiarch images (linux/amd64 and linux/arm64). Longer term we plan to make our official images multi arch and stop releasing the preview images, but we are not yet there. Multi arch preview images: * preview multi arch JDK11 S2I builder image. * preview multi arch JDK17 S2I builder image. * preview JDK11 multi arch runtime image. * preview JDK17 multi arch runtime image. NEW S2I BUILD WORKFLOW In order to create a server to be installed into the WildFly image we are relying on the that can now provision a fully configured server containing your deployment. The WildFly Maven plugin 3.0.0.Final has been evolved with some new goals to provision, configure, and package the server and the deployment in one step. When designing your application pom file, add an execution of the WildFly Maven plugin package goal, configure it with the and , and optionally reference WildFly CLI scripts to be executed and content to be copied inside the server. At the end of the build you will get (by default in the target/server directory) a server with your app deployed, ready to be installed in the image. In order to allow for a smooth transition to the new images, we are still supporting (in a deprecated way) the legacy workflow. Your existing application would work, but you are now required to specify the Galleon feature-pack(s) and layer(s) (GALLEON_PROVISION_FEATURE_PACKS and GALLEON_PROVISION_LAYERS env variables) you want to provision during the S2I build. EXECUTION TIME SERVER CONFIGURATION Application images built from the WildFly S2I builder or runtime images both expose the same API allowing you to fine tune the server execution. This API is exposed by means of environment variables to be set when configuring your deployment. JVM CONFIGURATION API The JVM that are used today with WildFly s2i images are still supported. They are a nice way to tune the JVM. WILDFLY SERVER STARTUP CONFIGURATION API The new server startup configuration API is described in this . This API comes with default values that should cover the main use-cases. 2 env variables open-up new possibilities: * SERVER_ARGS allows you to pass WildFly server arguments when starting the server. * CLI_LAUNCH_SCRIPT allows you to provide a path (relative to JBOSS_HOME or absolute) to a CLI script to be executed at startup time. Although CLI scripts should be executed at build time from the WildFly Maven plugin, in some cases it can be useful to adjust the configuration at execution time. You can package a set of CLI scripts inside your server at build time, then reference one of these CLI scripts to be executed at runtime. WILDFLY SERVER SUBSYSTEMS CONFIGURATION API If you are using WildFly s2i images you are perhaps asking yourself where are the env variables you have been using to configure the elytron subsystem, to add datasources, to configure logging or the microprofile-config subsystem,… They are provided by means of a new that you can combine with the WildFly Galleon feature-pack at build time to produce a server supporting these env variables. * If you only provision org.wildfly:wildfly-galleon-pack:26.1.0.Final you will get a "vanilla" WildFly server that will get lightly adjusted by the image entrypoint to properly execute on OpenShift. * If you provision org.wildfly:wildfly-galleon-pack:26.1.0.Final and org.wildfly.cloud:wildfly-cloud-galleon-pack:1.0.0.Final you will get a WildFly server for cloud execution ready to be configured thanks to the the cloud feature-pack exposes. 2 variants exist of the cloud feature-pack: * org.wildfly.cloud:wildfly-cloud-galleon-pack to be used with org.wildfly:wildfly-galleon-pack to provision an EE8 server as shown in this . * org.wildfly.cloud:wildfly-preview-cloud-galleon-pack to be used with org.wildfly:wildfly-preview-feature-pack to provision a Jakarta EE9 server as shown in this . Detailed documentation can be found . EXAMPLES We have defined a set of to help you get started. They cover different use-cases that highlight the new capabilities. The examples rely on to automate the build and deployment on OpenShift. In order to deploy the examples onto OpenShift, you can log in to the . The use cases covered are: * , an application that interacts with a postgresql database. The projects shows how to provision a server configured in a way that is similar to the default WildFly server presents in the legacy WildFly cento7 image. * , highlights the steps needed to build a docker image that contains the server and your application. * , simple application. * . Use WildFly elytron-oidc-client to interact with a Keycloak server. Also highlights the ability to provide server arguments at launch time. * . We all need to enable logging at some point. With a simple CLI script executed at server boot time, enable logging and redirect all traces to the CONSOLE. * . Create a WildFly application with support for postgreSQL database. * . Create a WildFly application with support for postgreSQL database. The running server and application are both compliant with Jakarta EE9. * . A cluster of PODS that share web sessions. This example benefits from the WildFly cloud feature-pack and Helm Chart for WildFly capabilities to automatically enable the dns.DNS_PING JGroups protocol and generate the ping service. ENJOY! and… keep us posted with your feedback. (You can log these as new .) Thank-you! JF Denise</content><dc:creator>Jean-François Denise</dc:creator></entry><entry><title type="html">RESTEasy Releases</title><link rel="alternate" href="https://resteasy.github.io/2022/04/19/resteasy-releases/" /><author><name /></author><id>https://resteasy.github.io/2022/04/19/resteasy-releases/</id><updated>2022-04-19T18:11:11Z</updated><dc:creator /></entry></feed>
