<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0" uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title type="html">Kogito 1.20.0 released!</title><link rel="alternate" href="https://blog.kie.org/2022/04/kogito-1-20-0-released.html" /><author><name>Cristiano Nicolai</name></author><id>https://blog.kie.org/2022/04/kogito-1-20-0-released.html</id><updated>2022-04-22T01:25:16Z</updated><content type="html">We are glad to announce that the Kogito 1.20.0 release is now available! This goes hand in hand with , release. From a feature point of view, we included a series of new features and bug fixes, including: * SpringBoot upgrade to version 2.6.6 * [Serverless Workflows] Implement AuthRef property for function definitions to retrieve OpenAPI Documents * [Serverless Workflows] Support Oauth2 for legacy REST Operations * [Operator] Operator now supports users to define their own Kogito deployment using a plain k8s Deployment object by annotating it with kogito.kie.org/runtime: ‘true’. * [Operator] Operator will now create a ConfigMap for every deployed supporting service, e.g. Management Console, allowing users to configure it easily. For more details head to the complete . All artifacts are available now: * Kogito runtime artifacts are available on Maven Central. * Kogito examples can be found . * Kogito images are available on . * Kogito operator is available in the in OpenShift and Kubernetes. * Kogito tooling 0.18.0 artifacts are available at the . A detailed changelog for 1.20.0 can be found in . New to Kogito? Check out our website . Click the "Get Started" button. The post appeared first on .</content><dc:creator>Cristiano Nicolai</dc:creator></entry><entry><title type="html">Create dashboards using YML with Dashbuilder</title><link rel="alternate" href="https://blog.kie.org/2022/04/create-dashboards-using-yml-with-dashbuilder.html" /><author><name>William Siqueira</name></author><id>https://blog.kie.org/2022/04/create-dashboards-using-yml-with-dashbuilder.html</id><updated>2022-04-21T21:55:00Z</updated><content type="html">Creating a dashboard using pure YML from data from any JSON document is now possible using Dashbuilder! You are not even required to install anything, just access and start your dashboard! HOW IT WAS POSSIBLE Dashbuilder was and the client was decoupled from the backend. With this change Dashbuilder could run on client only, without the requirement of a backend. On the client side can be used without the need of a backend. Naturally Dashbuilder could be used as an editor for its native dashboard definition format: JSON. However, the native format requires deep technical knowledge of how Dashbuilder works, hence multiple changes were made to make the JSON friendly to humans.  The JSON support was ready, however the YAML is easy to read and is a popular format due the use with Openshift and Kubernetes, so we decided to also support YAML, which is the conversion from JSON.  Currently we have an but a new one compatible with is in development! WHAT ABOUT DASHBUILDER AUTHORING The old Dashbuilder Authoring is in maintenance mode, which means that it continues to be released and we will fix critical issues, but new features will prioritize the YAML editor. HOW TO GET STARTED A can be found in Dashbuilder documentation. We have a few samples on the as well. The example library will grow soon, so stay tuned! The post appeared first on .</content><dc:creator>William Siqueira</dc:creator></entry><entry><title type="html">Narayana on the Cloud - Part 1</title><link rel="alternate" href="https://jbossts.blogspot.com/2022/04/narayana-on-cloud-part-1.html" /><author><name>Manuel Finelli</name></author><id>https://jbossts.blogspot.com/2022/04/narayana-on-cloud-part-1.html</id><updated>2022-04-21T17:05:00Z</updated><content type="html">In the last few months, I have been working on how distributed transactions are recovered in WildFly when this Application Server (AS) is deployed in Kubernetes. This blog post is a reflection on how Narayana performs on the cloud and the features it is still missing for it to evolve into a native cloud transaction suite. SOME (VERY BRIEF) CONTEXT Narayana started its journey more than 30 years ago! ArjunaCore was developed in the late 1980s. Even though the theoretical concept of cloud computing was introduced by John McCarthy in 1961 [1][2], at the time of ArjunaCore’s development it was still considered only as a theoretical possibility. However, in the past two decades, the implementation of cloud computing has increased exponentially, dramatically changing the world of technology. As a consequence, Narayana (and its ArjunaCore) needs to step up its game to become a cloud native transaction suite that can be used in different cloud environments. This is an ongoing conversation the Narayana team has started a long time ago (for a detailed summary of Narayana's Cloud Strategy see [3]). Narayana was introduced to the cloud through WildFly (note 1) on Kubernetes (K8s). In my recent experience, I worked on WildFly and its K8s operator [4] and I think that the integration between Narayana and WildFly works very smoothly on K8s [5]. On the other hand, when the pod hosting WildFly needs to scale down, the ephemeral nature of K8s does not get along with Narayana very well. In fact, ArjunaCore/Narayana needs to have a stable ground to perform its magic (within or without WildFly). In particular, Narayana needs to have: * A stable and durable Object Store where objects’ states are held * A stable node identifier to uniquely mark transactions (which are initialised by the Transaction Manager (TM) with the same node identifier) and ensure that the Recovery Manager will only recover those transactions * A stable communication channel to allow participants of transactions to communicate with the TM In all points above, “stable” indicates the ability to survive whatever happens to the host where Narayana is running (e.g., crashes). On the other hand, K8s is an ephemeral environment where pods do not need a stable storage and/or particular configurations that survive over multiple reboots. To overcome this “incompatibility”, K8s provides StatefulSet [6] through which applications can leverage a stable realm. Particularly in relation to Narayana, the employment of StatefulSet and the addition of a transaction recovery module to the WildFly K8s Operator [7] enables this AS to fully support transactions on K8s. Unfortunately, this solution is tailor-made for K8s and it cannot be easily ported in other cloud environments. Our target, though, is to evolve Narayana to become a cloud transaction suite, which means that Narayana should also support other cloud computing infrastructures. OUR TAKE ON THIS The Naryana team thoroughly discussed the above limitations that prevent Narayana from becoming a native cloud application. A brief summary is presented here: * A stable and durable Object Store where objects’ states are held Narayana is able to use different kinds of object stores; in particular, it is possible to use a (SQL) database to create the object store [8]. RDBMS databases are widely available on cloud environments: these solutions already cover our stability needs providing a reliable storage solution that supports replications and that is able to scale up on demand. Moreover, using a “centralised” RDBMS database would easen the management of multiple Narayana instances, which can be connected to the same database. This might also become incredibly useful in the future when it comes to evolving Narayana to work with multiple instances behind a load balancer (i.e. in case of replication)  * A stable communication channel to allow participants of transactions to communicate with the TM Most cloud providers (and platforms) already offer two options to tackle this problem: a stable IP address and a DNS. Although both methods still need some tweaking for each cloud provider, these solutions should provide a stable endpoint to communicate with Narayana’s TM over multiple reboots  * A stable node identifier to uniquely mark transactions (which are initialised by the Transaction Manager (TM) with the same node identifier) and ensure that the Recovery Manager will only recover those transactions This is the actual sticky point this blog post is about. Although it seems straightforward to assign a unique node identifier to the TM, it is indeed the first real logic challenge to solve on the path to turn Narayana in a cloud transaction manager We discussed different possible solutions to this last point but we are still trying to figure out how to address this issue. The main problem is that Narayana needs stable storage to save the node identifier and reload it after a reboot. As already said, cloud environments do not provide this option very easily as their ephemeral nature is more inclined to a stateless approach. Our first idea to solve this problem was, “why do we not store the node identifier in the object store? Narayana still needs a stable object store (and this constraint cannot be dropped) and RDBMS databases on the cloud already provide a base to start from”. The node identifier is a property of the transaction manager that gets initialised when Narayana/ArjunaCore starts (together with all the other properties). As a consequence, it is not possible to save the node identifier in the object store as the preferences for the object store are also loaded during the same initialisation process! In other words, if the node identifier is stored in the object store, how can Narayana/ArjunaCore know where the object store is without loading all properties? Which came first: the chicken or the egg? Nevertheless, introducing an order when properties are loaded might help in this regard (i.e. we force the egg to exist before the chicken). Nevertheless, there is still a problem: what happens if the object store is shared between different instances of Narayana/ArjunaCore? For example, it might be very likely that a Narayana administrator configures multiple Narayana instances to create their object stores in the same database. In this case, every Narayana instance would need a unique identifier to tell which node identifier in the object store is its own. Recursive problems are fun :-) Even if we solve all these problems, the assignment of the node identifier should not be possible outside of Narayana (e.g. using system properties) and it should become an exclusive (internal) operation of Narayana. Fortunately, this is easier than solving our previous “chicken and egg” problem as there are solutions to generate a unique distributed identifier locally [9]. As things stand, we should find an alternative solution to port the node identifier to the cloud. Looking at this problem from a different point of view, I wonder if there are more recent solutions to replace and/or remove the node identifier from Narayana. With this in mind, the first question I ask myself is “Why do we need a node identifier?”. Behind the hood, Narayana uses a recovery manager to try to recover transactions that have not completed their lifecycle. This comes with a caveat though: it is essential that two different recovery managers do not try to recover the same in-doubt transaction at the same time. That is where the node identifier comes in handy! In fact, thanks to the unique node identifier (that gets embedded in every global transaction identifier), the recovery manager can recognise if it is responsible for the recovery of an in-doubt transaction stored in a remote resource (note 2). This concept is best illustrated by an example. Let’s consider two different Narayana instances that initiate two different transactions that enlist the same resource. In this scenario, both transaction managers store a record in the shared resource. Let’s assume that the first Narayana instance starts the transaction before the second instance. While the first transaction gets to the point where it has sent prepare() to its enlisted resources, it is possible that the recovery manager of the second Narayana instance queries the shared resource for in-doubt records. If Naryana’s recovery manager was not forced to recover only transactions initiated by the same Narayana instance’s TM, this hypothetical scenario would have ended with an error: the recovery manager of the second Narayana instance would have rolled back the transaction initiated by the first Narayana instance, assuming that it was one of its own in-doubt transaction! Cloud environments are encouraging (all of) us to come up with an innovative solution to reduce the footprint of Narayana/ArjunaCore. In particular, the node identifier is the challenge we are currently facing and the first real step to push Narayana onto the cloud. I will share any updates the Narayana team comes up with…and in the meantime, feel free to reach out to the team through our public channels (for example Gitter or our Google group narayana-users) to propose your ideas or discuss with us your take on this fundamental issue. NOTE 1. WildFly supports transactions thanks to the integration with Narayana 2. It is possible to tell the Recovery Manager that it will be responsible for the recovery of in-doubt transactions initiated by different transaction managers (which are identified with different node identifiers). The only caveat here is that two Recovery Managers should not recover the same in-doubt transaction at the same time. To assign the responsibility of multiple node identifiers to the same Recovery Manager, the property xaRecoveryNodes [10] in Narayana’s JTAEnvironmentBean should be used. BIBLIOGRAPHY [1] J. Surbiryala and C. Rong, "Cloud Computing: History and Overview," 2019 IEEE Cloud Summit, 2019, pp. 1-7, doi: 10.1109/CloudSummit47114.2019.00007. [2] Garfinkel, Simson L. and Harold Abelson. “Architects of the Information Society: 35 Years of the Laboratory for Computer Science at Mit.” (1999). [3] https://jbossts.blogspot.com/2022/03/narayana-community-priorities.html [4] https://github.com/wildfly/wildfly-operator [5] https://issues.redhat.com/browse/EAP7-1394 [6] https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/ [7] https://github.com/wildfly/wildfly-operator/ [8] https://www.narayana.io/docs/project/index.html#d0e459 [9] https://groups.google.com/g/narayana-users/c/ttSff9HvXdA [10] https://www.narayana.io//docs/product/index.html#d0e1032</content><dc:creator>Manuel Finelli</dc:creator></entry><entry><title type="html">Getting started with Jakarta RESTful Services</title><link rel="alternate" href="http://www.mastertheboss.com/jboss-frameworks/resteasy/getting-started-with-jakarta-restful-services/" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/jboss-frameworks/resteasy/getting-started-with-jakarta-restful-services/</id><updated>2022-04-21T16:44:56Z</updated><content type="html">The latest release of RESTEasy (6.1.0) provides an overview of what’s coming with Jakarta RESTful Web Services 3.1. which will be a core component of Jakarta EE 10. Let’s review through this article the upcoming features using RESTEasy (6.1.0) implementation. What’s new in Jakarta RESTful Web Services 3.1 One of the top features of the ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title>Add security to a Quarkus application using Red Hat's SSO</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/04/21/add-security-quarkus-application-using-red-hats-sso" /><author><name>Olivier Rivat</name></author><id>7436626c-5883-4085-b1db-1dd801c7eca5</id><updated>2022-04-21T07:00:00Z</updated><published>2022-04-21T07:00:00Z</published><summary type="html">&lt;p&gt;&lt;a href="https://developers.redhat.com/products/quarkus/overview"&gt;Quarkus&lt;/a&gt; applications, like many other &lt;a href="https://developers.redhat.com/topics/enterprise-java"&gt;Java&lt;/a&gt; applications in use today, run on the network and require user authentication. If you are developing a Quarkus application that will run on a &lt;a href="https://developers.redhat.com/openshift"&gt;Red Hat OpenShift&lt;/a&gt; or &lt;a href="https://developers.redhat.com/products/rhel"&gt;Red Hat Enterprise Linux&lt;/a&gt; platform, you can add security quickly and easily through &lt;a href="https://access.redhat.com/products/red-hat-single-sign-on"&gt;Red Hat's single sign-on&lt;/a&gt; (SSO) technology. This article takes you through the steps, with an example Quarkus application deployed on Red Hat Enterprise Linux.&lt;/p&gt; &lt;h2&gt;Create a Quarkus project&lt;/h2&gt; &lt;p&gt;The procedure in this article uses a simple example application from the &lt;a href="https://quarkus.io/guides/getting-started"&gt;Quarkus guide&lt;/a&gt;. You can install the example using Maven:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ mvn io.quarkus.platform:quarkus-maven-plugin:2.7.1.Final:create \ -DprojectGroupId=org.acme \ -DprojectArtifactId=getting-started \ -Dextensions="resteasy"&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This application is deployed in the &lt;code&gt;getting-started&lt;/code&gt; directory, so go to that directory:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ cd getting-started&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Start the application in dev mode:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ mvn quarkus:dev&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;You can make sure that the application is installed by visiting its URL &lt;code&gt;http://localhost:8080/hello&lt;/code&gt; on your local system, either in a browser or from the command line:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ curl -w "\n" http://localhost:8080/hello Hello RESTEasy&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Prepare Red Hat's SSO&lt;/h2&gt; &lt;p&gt;As you saw in that listing, when you visit this URL, the sample Quarkus application will display a message that says "Hello RESTEasy". In the rest of this article, you'll learn how to secure this Quarkus URL using Red Hat's single sign-on technology. To do so, you'll need to register the Quarkus application as a Red Hat single sign-on client.&lt;/p&gt; &lt;p&gt;With single sign-on in place, any browser call to the Quarkus application's URL &lt;code&gt;http://localhost:8080/hello&lt;/code&gt; will redirect the user to the single sign-on authentication server at &lt;code&gt;http://localhost:8180/auth&lt;/code&gt;. Only after the user authenticates will they be redirected back to the greeting from the Quarkus application.&lt;/p&gt; &lt;p&gt;As you can tell from the URLs, the Quarkus application communicates over the default web port 8080, and Red Hat's SSO therefore has to be started on a different port. The following command starts the SSO on port 8180:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ sh standalone.sh -Djboss.socket.binding.port-offset=100&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Go to the console for Red Hat's SSO at &lt;code&gt;http://localhost:8180/auth/admin/&lt;/code&gt;. Create a realm called &lt;code&gt;quarkus&lt;/code&gt; and add a user named &lt;code&gt;user1&lt;/code&gt; to this realm (Figure 1).&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/user_2.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/user_2.png?itok=KYyG5sWA" width="947" height="610" alt="You can configure a realm and a user in Red Hat's SSO console." loading="lazy" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1. You can configure a realm and a user in Red Hat's SSO console. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 1: You can configure a realm and a user in Red Hat's SSO console.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Configure the Quarkus application to authenticate with Red Hat's SSO&lt;/h2&gt; &lt;p&gt;Also within the &lt;code&gt;quarkus&lt;/code&gt; realm, create a client named &lt;code&gt;hello&lt;/code&gt; (Figure 2). This corresponds to the Quarkus example application you've installed. Configure the client's access type as &lt;strong&gt;confidential.&lt;/strong&gt;&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/hello.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/hello.png?itok=7OZ7NaOi" width="1412" height="960" alt="The Hello application should be made confidential in Red Hat's SSO console." loading="lazy" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 2. The Hello application should be made confidential in Red Hat's SSO console. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 2: The Hello application should be made confidential in Red Hat's SSO console.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;This &lt;code&gt;hello&lt;/code&gt; client uses a client ID and secret for authentication. The client secret is generated by Red Hat's SSO (Figure 3), and you need to copy the secret for later use.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/secret.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/secret.png?itok=OcG7zDnj" width="1215" height="362" alt="Red Hat's SSO console generates a secret for the Hello application." loading="lazy" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 3. Red Hat's SSO console generates a secret for the Hello application. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 3: Red Hat's SSO console generates a secret for the Hello application.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Update the Quarkus application and configuration&lt;/h2&gt; &lt;p&gt;Your application communicates using &lt;a href="https://openid.net/connect/"&gt;OpenID Connect&lt;/a&gt; (OICD), so add the OIDC extension to your Quarkus project:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ ./mvnw quarkus:add-extension -Dextensions="oidc" &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Relaunch the application in debug mode:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ mvn quarkus:dev&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Then update the &lt;code&gt;application.properties&lt;/code&gt; file to integrate Red Hat's SSO. Supply the appropriate values for your instance of the application when setting the following variables:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;code&gt;quarkus.oidc.client-id&lt;/code&gt;: Client ID of the application&lt;/li&gt; &lt;li&gt;&lt;code&gt;quarkus.oidc.credentials.secret&lt;/code&gt;: Client secret of the application&lt;/li&gt; &lt;li&gt;&lt;code&gt;quarkus.oidc.auth-server-url&lt;/code&gt;: URL of the application&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;The lines related to authentication and OIDC should look like the following, though you should swap in the proper values for your application:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt;quarkus.oidc.auth-server-url=http://localhost:8180/auth/realms/quarkus quarkus.oidc.client-id=hello quarkus.oidc.credentials.secret=ec7200d9-ccb3-4335-ac72-d2ccd2aab190 quarkus.oidc.application-type=web-app quarkus.http.auth.permission.authenticated.paths=/* quarkus.http.auth.permission.authenticated.policy=authenticated&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;For more information about these properties, see the &lt;a href="https://quarkus.io/guides/security-openid-connect-web-authentication#quarkus-oidc_configuration"&gt;Quarkus configuration reference&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Any further calls to this Quarkus application will now redirect the user to Red Hat's SSO for authentication.&lt;/p&gt; &lt;h2&gt;Test the application with Red Hat's SSO&lt;/h2&gt; &lt;p&gt;Now you can visit your application's URL again and see that authentication is in place.&lt;/p&gt; &lt;h3&gt;Browser testing&lt;/h3&gt; &lt;p&gt;Browser testing invokes Red Hat's SSO standard flow, which uses an &lt;a href="https://datatracker.ietf.org/doc/html/rfc6749#section-4.1"&gt;OAuth 2.0 authorization code grant&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Just enter &lt;code&gt;http://localhost:8080/hello&lt;/code&gt; into a browser window. You should be redirected to the &lt;code&gt;quarkus&lt;/code&gt; realm in Red Hat's SSO, where you need to authenticate as &lt;code&gt;user1&lt;/code&gt;. The following credentials are used for this example:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Username: &lt;code&gt;user1&lt;/code&gt;&lt;/li&gt; &lt;li&gt;Password: &lt;code&gt;password&lt;/code&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;REST API testing&lt;/h3&gt; &lt;p&gt;When you test the application by issuing REST API queries from the command line, you invoke Red Hat's SSO direct access grant flow, which uses an &lt;a href="https://datatracker.ietf.org/doc/html/rfc6749#section-4.3"&gt;OAuth 2.0 read-only password grant&lt;/a&gt;. It delivers&lt;em&gt; &lt;/em&gt;an&lt;em&gt; access token&lt;/em&gt; and a &lt;em&gt;refresh token&lt;/em&gt; in its response to the query:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ curl -d "client_id=hello" -d client_secret=ec7200d9-ccb3-4335-ac72-d2ccd2aab190 -d "username=user1" -d "password=password" -d "grant_type=password" "http://localhost:8180/auth/realms/quarkus/protocol/openid-connect/token" | jq { "access_token": "eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJoMHhOVEV1Y3drcWdSNkd3TEkxVXVHcExGLVBjTU1sWnROdDBabGYyM2hnIn0.eyJleHAiOjE2NDcyNjQ5MjIsImlhdCI6MTY0NzI2NDYyMiwianRpIjoiMWQ3MmE2NDYtNzc2NS00MWJkLWFmZmQtZjNhMmEyZGM1MTM0IiwiaXNzIjoiaHR0cDovL2xvY2FsaG9zdDo4MTgwL2F1dGgvcmVhbG1zL3F1YXJrdXMiLCJhdWQiOiJhY2NvdW50Iiwic3ViIjoiYzkwN2M2N2UtZDc2Ny00ZGRlLWI5N2UtOWVhMmY1NTYzOGVlIiwidHlwIjoiQmVhcmVyIiwiYXpwIjoiaGVsbG8iLCJzZXNzaW9uX3N0YXRlIjoiM2NlMWM0YWEtMDE5Yy00MGExLWFkMDEtYWJjYzJmYmNhZTEwIiwiYWNyIjoiMSIsImFsbG93ZWQtb3JpZ2lucyI6WyJodHRwOi8vbG9jYWxob3N0OjgwODAiXSwicmVhbG1fYWNjZXNzIjp7InJvbGVzIjpbIm9mZmxpbmVfYWNjZXNzIiwiZGVmYXVsdC1yb2xlcy1xdWFya3VzIiwidW1hX2F1dGhvcml6YXRpb24iXX0sInJlc291cmNlX2FjY2VzcyI6eyJhY2NvdW50Ijp7InJvbGVzIjpbIm1hbmFnZS1hY2NvdW50IiwibWFuYWdlLWFjY291bnQtbGlua3MiLCJ2aWV3LXByb2ZpbGUiXX19LCJzY29wZSI6ImVtYWlsIHByb2ZpbGUiLCJzaWQiOiIzY2UxYzRhYS0wMTljLTQwYTEtYWQwMS1hYmNjMmZiY2FlMTAiLCJlbWFpbF92ZXJpZmllZCI6ZmFsc2UsInByZWZlcnJlZF91c2VybmFtZSI6InVzZXIxIn0.SN8xZevRdFba6oB4fWIrde4I75U5osTZsvhw6bZjGnwer-bVcTNEtlokNEk3Ro5LsqtPEQ7by7ZdCKwnWHuPPC0EGqS8p4Kskfh20DdTx1NzboabKujv3d7JnkoEg3QPNsIzhHz3Hx095mZTf9KwAXQrtUwKk50xCtfQCccWLV5RMzuVlQ0z1s4wS0t_9PF-G_aNwK-evpHTuHPUrTV_A71bLcaaRDrUSgG9ux1-yJNGa_pHoT3-au0lOMix3d6DRUesFzLkESrIK6_OIvqk4bFToQCQDq48YvZKZlOnAwDWIv5KJ8m3X3TnmUmXa_YiUugQlYmZC0Jk49tIU0_SPQ", "expires_in": 300, "refresh_expires_in": 1800, "refresh_token": "eyJhbGciOiJIUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICI0NmViYTE1Ni02ZDgyLTQ1NTMtOWI3Zi1kNjM2Yjk3MjFhYjEifQ.eyJleHAiOjE2NDcyNjY0MjIsImlhdCI6MTY0NzI2NDYyMiwianRpIjoiODY3M2RhNTUtYmNjYi00YjczLWEzYzctZjQ1ZWQyOTkyZTU4IiwiaXNzIjoiaHR0cDovL2xvY2FsaG9zdDo4MTgwL2F1dGgvcmVhbG1zL3F1YXJrdXMiLCJhdWQiOiJodHRwOi8vbG9jYWxob3N0OjgxODAvYXV0aC9yZWFsbXMvcXVhcmt1cyIsInN1YiI6ImM5MDdjNjdlLWQ3NjctNGRkZS1iOTdlLTllYTJmNTU2MzhlZSIsInR5cCI6IlJlZnJlc2giLCJhenAiOiJoZWxsbyIsInNlc3Npb25fc3RhdGUiOiIzY2UxYzRhYS0wMTljLTQwYTEtYWQwMS1hYmNjMmZiY2FlMTAiLCJzY29wZSI6ImVtYWlsIHByb2ZpbGUiLCJzaWQiOiIzY2UxYzRhYS0wMTljLTQwYTEtYWQwMS1hYmNjMmZiY2FlMTAifQ.lrrq_toV92cf2mzJoWRrUs7MteCXgF_MFgdNlJ3o82A", "token_type": "Bearer", "not-before-policy": 0, "session_state": "3ce1c4aa-019c-40a1-ad01-abcc2fbcae10", "scope": "email profile" }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;It is also possible to display the details of the access token:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ access_token=`curl -d "client_id=hello" -d client_secret=ec7200d9-ccb3-4335-ac72-d2ccd2aab190 -d "username=user1" -d "password=password" -d "grant_type=password" "http://localhost:8180/auth/realms/quarkus/protocol/openid-connect/token" | jq -r .access_token` echo $access_token | cut -d"." -f2 | base64 -d | jq base64: invalid input { "exp": 1647265083, "iat": 1647264783, "jti": "073295d8-1829-4f01-a58f-0d6497782ddd", "iss": "http://localhost:8180/auth/realms/quarkus", "aud": "account", "sub": "c907c67e-d767-4dde-b97e-9ea2f55638ee", "typ": "Bearer", "azp": "hello", "session_state": "4b15f101-efce-4c8e-8206-beba5e06e7fc", "acr": "1", "allowed-origins": [ "http://localhost:8080" ], "realm_access": { "roles": [ "offline_access", "default-roles-quarkus", "uma_authorization" ] }, "resource_access": { "account": { "roles": [ "manage-account", "manage-account-links", "view-profile" ] } }, "scope": "email profile", "sid": "4b15f101-efce-4c8e-8206-beba5e06e7fc", "email_verified": false, "preferred_username": "user1" }&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;This simple example has shown how easy it is to add security to a Quarkus application with Red Hat's SSO. Quarkus applications can be secured with Red Hat's SSO just as enterprise Java applications can.&lt;/p&gt; &lt;p&gt;For further information about Quarkus application security, please read the &lt;a href="https://quarkus.io/guides/#security"&gt;security sections of the Quarkus guide&lt;/a&gt;. To learn more about using Red Hat's single sign-on technology, check out my earlier articles on Red Hat Developer:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2021/05/19/deploy-red-hats-single-sign-technology-red-hat-openshift-using-templates"&gt;Deploy Red Hat's single sign-on technology on Red Hat OpenShift using templates&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2021/03/25/integrate-red-hats-single-sign-on-technology-7-4-with-red-hat-openshift"&gt;Deploy Red Hat’s single sign-on technology 7.4 with Red Hat OpenShift&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2021/02/19/x-509-user-certificate-authentication-with-red-hats-single-sign-on-technology"&gt;X.509 user certificate authentication with Red Hat's single sign-on technology&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/04/21/add-security-quarkus-application-using-red-hats-sso" title="Add security to a Quarkus application using Red Hat's SSO"&gt;Add security to a Quarkus application using Red Hat's SSO&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Olivier Rivat</dc:creator><dc:date>2022-04-21T07:00:00Z</dc:date></entry><entry><title>Deploy Keycloak single sign-on with Ansible</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/04/20/deploy-keycloak-single-sign-ansible" /><author><name>Romain Pelisse</name></author><id>7f17be01-c88d-45b6-be02-71b1f3b07f0b</id><updated>2022-04-20T07:00:00Z</updated><published>2022-04-20T07:00:00Z</published><summary type="html">&lt;p&gt;This article is the fourth installment in our series on &lt;a href="https://developers.redhat.com/products/ansible/overview"&gt;Ansible&lt;/a&gt; for middleware. In this article, you'll use Ansible to simplify and automate the installation of &lt;a href="https://www.redhat.com/en/blog/getting-started-keycloak-single-sign-operator"&gt;Keycloak&lt;/a&gt;, a popular &lt;a href="https://developers.redhat.com/topics/open-source"&gt;open source&lt;/a&gt; tool to implement single sign-on for Web applications. The previous articles in this series are:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2021/08/30/automate-red-hat-jboss-web-server-deployments-ansible"&gt;Automate Red Hat JBoss Web Server deployments with Ansible&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/02/08/automate-and-deploy-jboss-eap-cluster-ansible"&gt;Automate and deploy a JBoss EAP cluster with Ansible&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/03/21/deploy-infinispan-automatically-ansible"&gt;Deploy Infinispan automatically with Ansible&lt;/a&gt;&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;The tutorial in this article builds on an Ansible Collection named &lt;a href="https://galaxy.ansible.com/middleware_automation/keycloak"&gt;middleware_automation.keycloak&lt;/a&gt;, which has been specifically designed for this endeavor.&lt;/p&gt; &lt;h2&gt;Prerequisites&lt;/h2&gt; &lt;p&gt;To make use of this tutorial, you need a &lt;a href="https://developers.redhat.com/products/rhel"&gt;Red Hat Enterprise Linux&lt;/a&gt; or &lt;a href="https://getfedora.org"&gt;Fedora&lt;/a&gt; system, along with version 2.9 or higher of Ansible (preferably the latest version).&lt;/p&gt; &lt;h2&gt;Install the collection&lt;/h2&gt; &lt;p&gt;The very first step, of course, is to install the collection itself, so that Ansible can use its content inside playbooks:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ ansible-galaxy collection install middleware_automation.keycloak Starting galaxy collection install process Process install dependency map Starting collection install process Downloading https://galaxy.ansible.com/download/middleware_automation-keycloak-1.0.0.tar.gz to /root/.ansible/tmp/ansible-local-24nzydu97b/tmpaql0qbek/middleware_automation-keycloak-1.0.0-8yma1_vi Installing 'middleware_automation.keycloak:1.0.0' to '/root/.ansible/collections/ansible_collections/middleware_automation/keycloak' Downloading https://galaxy.ansible.com/download/middleware_automation-redhat_csp_download-1.2.1.tar.gz to /root/.ansible/tmp/ansible-local-24nzydu97b/tmpaql0qbek/middleware_automation-redhat_csp_download-1.2.1-4po4eg4w middleware_automation.keycloak:1.0.0 was installed successfully Installing 'middleware_automation.redhat_csp_download:1.2.1' to '/root/.ansible/collections/ansible_collections/middleware_automation/redhat_csp_download' Downloading https://galaxy.ansible.com/download/middleware_automation-wildfly-1.0.1.tar.gz to /root/.ansible/tmp/ansible-local-24nzydu97b/tmpaql0qbek/middleware_automation-wildfly-1.0.1-ayf0n_nq middleware_automation.redhat_csp_download:1.2.1 was installed successfully Installing 'middleware_automation.wildfly:1.0.1' to '/root/.ansible/collections/ansible_collections/middleware_automation/wildfly' middleware_automation.wildfly:1.0.1 was installed successfully&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The collection has the following dependencies:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;code&gt;middleware_automation.redhat_csp&lt;/code&gt;: This collection allows Ansible to connect to the Red Hat Customer Portal to download &lt;a href="https://access.redhat.com/products/red-hat-single-sign-on"&gt;Red Hat's single sign-on technology&lt;/a&gt;, which is a productized and supported version of Keycloak. We won't use this feature in this article.&lt;/li&gt; &lt;li&gt;&lt;code&gt;middleware_automation.wildfly&lt;/code&gt;: Keycloak runs on top of the &lt;a href="https://www.wildfly.org"&gt;Wildfly&lt;/a&gt; application server, including &lt;a href="https://developers.redhat.com/products/eap/overview"&gt;Red Hat JBoss Enterprise Application Platform&lt;/a&gt; (JBoss EAP), which is the version of Wildfly supported by Red Hat. For more details about this collection, please refer to the second article in this series, &lt;a href="https://developers.redhat.com/articles/2022/02/08/automate-and-deploy-jboss-eap-cluster-ansible"&gt;Automate and deploy a JBoss EAP Cluster with Ansible&lt;/a&gt;.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;Depending on the configuration of the machine used as the Ansible controller, you might need to add some Python dependencies so that Ansible will have the libraries required to make use of the collection. Install them by running the following command:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt;# pip3 install lxml jmespath Collecting lxml Downloading lxml-4.7.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.9 MB) |████████████████████████████████| 6.9 MB 1.9 MB/s Collecting jmespath Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB) Installing collected packages: lxml, jmespath Successfully installed jmespath-0.10.0 lxml-4.7.1&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Before going further, you should check to make sure that the collection has been successfully installed. To do so, run the following command from Ansible Galaxy that will list all the installed collections.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note&lt;/strong&gt;: This collection list feature is available in Ansible Galaxy 2.12, but not 2.9.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;# ansible-galaxy collection list # /root/.ansible/collections/ansible_collections Collection Version ----------------------------------------- ------- middleware_automation.keycloak 1.0.1 middleware_automation.redhat_csp_download 1.2.1 middleware_automation.wildfly 1.0.2 &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Now that the collection and its dependencies are installed, you can use it in an automation:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt;--- - name: Playbook for keycloak Hosts hosts: keycloak collections: - middleware_automation.keycloak tasks:&lt;/code&gt;&lt;/pre&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note&lt;/strong&gt;: In order for this playbook to perform the installation outlined here, Ansible must have sudo or root privileges on the target hosts.&lt;/p&gt; &lt;h2&gt;Install Keycloak with Ansible&lt;/h2&gt; &lt;p&gt;Thanks to the dedicated collection you just installed, automating the installation and configuration of Keycloak is easy. However, before you implement this inside your playbook, we should recap what we mean here by &lt;em&gt;installing Keycloak.&lt;/em&gt; Indeed, this task encompasses quite a few operations that are performed on the target system:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Creating appropriate operating system user and group accounts (the name is &lt;code&gt;keycloak&lt;/code&gt; for both)&lt;/li&gt; &lt;li&gt;Downloading the installation archive from the Keycloak website&lt;/li&gt; &lt;li&gt;Unarchiving the content while ensuring that all the files are associated with the appropriate user and groups along with the correct privileges&lt;/li&gt; &lt;li&gt;Ensuring that the required version of the Java Virtual Machine (JVM) is installed&lt;/li&gt; &lt;li&gt;Integrating the software into the host service management system (in our case, the Linux &lt;a href="https://www.linux.com/training-tutorials/understanding-and-using-systemd/"&gt;systemd&lt;/a&gt; daemon).&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;All of this is achieved and is fully automated by the following short playbook:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt; - name: Playbook for Keycloak Hosts hosts: keycloak collections: - middleware_automation.keycloak tasks: - name: Include keycloak role ansible.builtin.include_role: name: middleware_automation.keycloak.keycloak vars: keycloak_admin_password: "changeme"&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The playbook begins by defining a variable for the Keycloak server administrative user. Note that, because this variable is a password, it should really be secured using &lt;a href="https://docs.ansible.com/ansible/latest/user_guide/vault.html"&gt;Ansible Vault&lt;/a&gt; or some other secrets management system. However, that task is beyond the scope of this article.&lt;/p&gt; &lt;p&gt;The configuration then adds the Ansible collection for Keycloak to the list used by the playbook and adds the associated &lt;code&gt;middleware_automation.keycloak.keycloak&lt;/code&gt; role to the list of roles that the playbook uses.&lt;/p&gt; &lt;p&gt;Run this playbook as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;# ansible-playbook -i inventory playbook.yml PLAY [Playbook for Keycloak Hosts] *************************************************************************************************************************** TASK [Gathering Facts] *************************************************************************************************************************************** ok: [localhost] TASK [middleware_automation.keycloak.keycloak : Validating arguments against arg spec 'main'] **************************************************************** ok: [localhost] TASK [middleware_automation.keycloak.keycloak : Check prerequisites] ***************************************************************************************** included: /root/.ansible/collections/ansible_collections/middleware_automation/keycloak/roles/keycloak/tasks/prereqs.yml for localhost TASK [middleware_automation.keycloak.keycloak : Validate configuration] … TASK [middleware_automation.keycloak.keycloak : Create keycloak admin user] ********************************************************************************** changed: [localhost] TASK [middleware_automation.keycloak.keycloak : Restart keycloak] ******************************************************************************************** included: /root/.ansible/collections/ansible_collections/middleware_automation/keycloak/roles/keycloak/tasks/restart_keycloak.yml for localhost TASK [middleware_automation.keycloak.keycloak : Restart and enable keycloak service] ************************************************************************ changed: [localhost] TASK [middleware_automation.keycloak.keycloak : Wait until keycloak becomes active http://localhost:9990/health] ********************************************* FAILED - RETRYING: [localhost]: Wait until keycloak becomes active http://localhost:9990/health (25 retries left). ok: [localhost] PLAY RECAP *************************************************************************************************************************************************** localhost : ok=44 changed=2 unreachable=0 failed=0 skipped=14 rescued=1 ignored=0 &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;More than forty tasks from the included role have been executed, taking care of all the requirements mentioned earlier: user and group creation, the software download, installing the required JVM, etc.&lt;/p&gt; &lt;h2&gt;Check for successful installation&lt;/h2&gt; &lt;p&gt;Once the playbook finishes its execution, you can confirm that Keycloak is now running as a service by verifying the status of the service:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;# ● keycloak.service - Keycloak Server Loaded: loaded (/etc/systemd/system/keycloak.service; enabled; vendor preset: disabled) Active: active (running) since Mon 2022-03-21 08:06:08 UTC; 3min 36s ago Process: 1553 ExecStop=/opt/keycloak/keycloak-service.sh stop (code=exited, status=0/SUCCESS) Process: 1571 ExecStart=/opt/keycloak/keycloak-service.sh start (code=exited, status=0/SUCCESS) Main PID: 1636 (java) Tasks: 79 (limit: 1638) Memory: 1012.8M CGroup: /system.slice/keycloak.service ├─1574 /bin/sh /opt/keycloak/keycloak-15.0.2/bin/standalone.sh -Djboss.bind.address=0.0.0.0 -Djboss.http.port=8080 -Djboss.https.port=8443 -Djboss.management.http.port=9990 -Djboss.management.https.port=9993 -Djboss.node.name=&gt; └─1636 java -D[Standalone] -server -Xms1024m -Xmx2048m -Dorg.jboss.boot.log.file=/opt/keycloak/keycloak-15.0.2/standalone/log/server.log -Dlogging.configuration=file:/opt/keycloak/keycloak-15.0.2/standalone/configuration/loggi&gt; Mar 21 08:06:17 7efa2c53bfe8 keycloak-service.sh[1571]: 08:06:17,566 INFO [org.jboss.resteasy.resteasy_jaxrs.i18n] (ServerService Thread Pool -- 65) RESTEASY002220: Adding singleton resource org.keycloak.services.resources.RobotsResourc&gt; Mar 21 08:06:17 7efa2c53bfe8 keycloak-service.sh[1571]: 08:06:17,567 INFO [org.jboss.resteasy.resteasy_jaxrs.i18n] (ServerService Thread Pool -- 65) RESTEASY002210: Adding provider singleton org.keycloak.services.util.ObjectMapperResolv&gt; Mar 21 08:06:17 7efa2c53bfe8 keycloak-service.sh[1571]: 08:06:17,567 INFO [org.jboss.resteasy.resteasy_jaxrs.i18n] (ServerService Thread Pool -- 65) RESTEASY002220: Adding singleton resource org.keycloak.services.resources.WelcomeResour&gt; Mar 21 08:06:17 7efa2c53bfe8 keycloak-service.sh[1571]: 08:06:17,567 INFO [org.jboss.resteasy.resteasy_jaxrs.i18n] (ServerService Thread Pool -- 65) RESTEASY002220: Adding singleton resource org.keycloak.services.resources.RealmsResourc&gt; Mar 21 08:06:17 7efa2c53bfe8 keycloak-service.sh[1571]: 08:06:17,650 INFO [org.wildfly.extension.undertow] (ServerService Thread Pool -- 65) WFLYUT0021: Registered web context: '/auth' for server 'default-server' Mar 21 08:06:17 7efa2c53bfe8 keycloak-service.sh[1571]: 08:06:17,728 INFO [org.jboss.as.server] (ServerService Thread Pool -- 43) WFLYSRV0010: Deployed "keycloak-server.war" (runtime-name : "keycloak-server.war") Mar 21 08:06:17 7efa2c53bfe8 keycloak-service.sh[1571]: 08:06:17,764 INFO [org.jboss.as.server] (Controller Boot Thread) WFLYSRV0212: Resuming server Mar 21 08:06:17 7efa2c53bfe8 keycloak-service.sh[1571]: 08:06:17,766 INFO [org.jboss.as] (Controller Boot Thread) WFLYSRV0025: Keycloak 15.0.2 (WildFly Core 15.0.1.Final) started in 9864ms - Started 596 of 873 services (584 services are&gt; Mar 21 08:06:17 7efa2c53bfe8 keycloak-service.sh[1571]: 08:06:17,768 INFO [org.jboss.as] (Controller Boot Thread) WFLYSRV0060: Http management interface listening on http://127.0.0.1:9990/management Mar 21 08:06:17 7efa2c53bfe8 keycloak-service.sh[1571]: 08:06:17,768 INFO [org.jboss.as] (Controller Boot Thread) WFLYSRV0051: Admin console listening on http://127.0.0.1:9990/code&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Note that the playbook execution itself verifies that the service is running and that the Keycloak server itself is also available:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;… TASK [middleware_automation.keycloak.keycloak : Restart and enable keycloak service] ************************************************** changed: [localhost] TASK [middleware_automation.keycloak.keycloak : Wait until keycloak becomes active http://localhost:9990/health] *********************** ok: [localhost]&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;However, for the sake of being thorough, you should double-check that the Keycloak port is indeed accessible:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;# curl -I http://localhost:9990/health HTTP/1.1 200 OK Connection: keep-alive Content-Type: application/json Content-Length: 283 Date: Fri, 18 Mar 2022 09:38:00 GMT&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;If you navigate to &lt;a href="http://localhost:8080/"&gt;http://localhost:8080/&lt;/a&gt;, you will have access to your fully ready installation of Keycloak (Figure 1).&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/key_0.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/key_0.png?itok=jT0wsq_e" width="1440" height="635" alt="The Keycloak administrative site is running on the local computer." loading="lazy" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1. The Keycloak administrative site is running on the local computer. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 1: The Keycloak administrative site should be running on your local computer.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;To summarize, at the end of this playbook execution, you'll have a running &lt;code&gt;systemd&lt;/code&gt; service managing an instance of Keycloak.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;By using Ansible and the Ansible Collection for Keycloak as outlined in this article, you can fully automate the deployment of a single sign-on server. In this article, Ansible has performed all the heavy lifting: downloading software, preparing the operating system (user, group, firewall), deploying the binary files and the configuration, setting up the service (&lt;code&gt;systemd&lt;/code&gt;), and even preparing the required administrative account. The Ansible Collection for Keycloak allows you to streamline the installation and configuration of Keycloak, thus enabling you to scale deployments as necessary and ensure repeatability across them all.&lt;/p&gt; &lt;p&gt;In an upcoming article, we'll discuss how to further automate Keycloak's single sign-on service by creating realms and their members using Ansible.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/04/20/deploy-keycloak-single-sign-ansible" title="Deploy Keycloak single sign-on with Ansible"&gt;Deploy Keycloak single sign-on with Ansible&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Romain Pelisse</dc:creator><dc:date>2022-04-20T07:00:00Z</dc:date></entry><entry><title>Solving problems with Quarkus extensions (1/n)</title><link rel="alternate" href="&#xA;                https://quarkus.io/blog/solving-problems-with-extensions/&#xA;            " /><author><name>Guillaume Smet (https://twitter.com/gsmet_)</name></author><id>https://quarkus.io/blog/solving-problems-with-extensions/</id><updated>2022-04-20T00:00:00Z</updated><published>2022-04-20T00:00:00Z</published><summary type="html">This is the first post of what I hope will be a series of several articles showing how you can solve complex problems by leveraging the unique Quarkus build infrastructure and extension framework. First things first, bootstraping a Quarkus extension is easy: in one command, you can get it scaffolded...</summary><dc:creator>Guillaume Smet (https://twitter.com/gsmet_)</dc:creator><dc:date>2022-04-20T00:00:00Z</dc:date></entry><entry><title type="html">RESTEasy Releases</title><link rel="alternate" href="https://resteasy.github.io/2022/04/19/resteasy-releases/" /><author><name /></author><id>https://resteasy.github.io/2022/04/19/resteasy-releases/</id><updated>2022-04-19T18:11:11Z</updated><dc:creator /></entry><entry><title type="html">How to manage Transactions in Quarkus</title><link rel="alternate" href="http://www.mastertheboss.com/soa-cloud/quarkus/how-to-manage-transactions-in-quarkus/" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/soa-cloud/quarkus/how-to-manage-transactions-in-quarkus/</id><updated>2022-04-19T10:40:44Z</updated><content type="html">This article launches you on a tour of Transaction Management in Quarkus applications by focusing on the standard declarative approach and the new programmatic transaction API. Quarkus narayana extension Quarkus, just like other Enterprise applications, uses a Transaction Manager to coordinate and expose transactions to your applications. At its core, Quarkus uses Narayana Transaction Manager, ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title>Java 17: What’s new in OpenJDK's container awareness</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/04/19/java-17-whats-new-openjdks-container-awareness" /><author><name>Severin Gehwolf</name></author><id>d5069613-6b53-421b-9e45-bf8cf43625de</id><updated>2022-04-19T07:00:00Z</updated><published>2022-04-19T07:00:00Z</published><summary type="html">&lt;p&gt;&lt;a href="https://developers.redhat.com/topics/enterprise-java"&gt;OpenJDK&lt;/a&gt; has been aware of &lt;a href="https://developers.redhat.com/topics/linux"&gt;Linux&lt;/a&gt; containers (such as &lt;a href="https://www.docker.com"&gt;Docker&lt;/a&gt; and &lt;a href="https://podman.io"&gt;Podman&lt;/a&gt;, as well as container orchestration frameworks such as &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt;) for some time. By &lt;em&gt;container awareness,&lt;/em&gt; we mean that OpenJDK detects when it is running inside a container. In this article, you'll learn why container awareness is useful, what has changed recently in that area of OpenJDK, and what diagnostic options are available to help developers gain insight into how the JVM determines settings.&lt;/p&gt; &lt;p&gt;OpenJDK's container awareness detection uses Linux's control group (cgroup) filesystem to detect enforced resource quotas. As of this writing, Java 17 is the only long-term support release that supports both &lt;a href="https://www.kernel.org/doc/html/latest/admin-guide/cgroup-v1/cgroups.html"&gt;cgroups v1&lt;/a&gt; and &lt;a href="https://www.kernel.org/doc/html/latest/admin-guide/cgroup-v2.html"&gt;cgroups v2&lt;/a&gt; configurations. Note, however, that there is currently work ongoing to backport cgroups v2 support to OpenJDK 11.&lt;/p&gt; &lt;p&gt;OpenJDK detects whether certain resource quotas are in place when running in a container and, if so, uses those bounds for its operation. These resource limits affect, for example, the garbage collection (GC) algorithm selected by the JVM, the default size of the heap, the sizes of thread pools, and how default parallelism is determined for &lt;code&gt;ForkJoinPool&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;OpenJDK container awareness has been available in Java 17 and Java 11 since their respective general availability (GA) releases, and in Java 8u starting with update 8u202.&lt;/p&gt; &lt;h2&gt;Why container awareness is important&lt;/h2&gt; &lt;p&gt;Kubernetes and many other popular cloud orchestration systems let deployments limit container resources via &lt;a href="https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#how-pods-with-resource-requests-are-scheduled"&gt;CPU and memory quotas&lt;/a&gt;. Those limits translate into options that are passed to the container engine when containers are deployed. Container engine options, in turn, set resource limits via the Linux cgroup pseudo-filesystem. The Linux kernel ensures that when resource limits are in place via the cgroup, no process goes beyond those limits (at least not for extended periods of time).&lt;/p&gt; &lt;p&gt;When Java processes are deployed in such an environment, cgroup limits might be set for the deployed process. If the Java Virtual Machine does not take configured cgroup limits into account, it might risk trying to consume more resources than the operating system is willing to provide to it. The result could be the unexpected termination of the Java process.&lt;/p&gt; &lt;h2&gt;Recent changes in OpenJDK's container awareness code&lt;/h2&gt; &lt;p&gt;Between Java 11 and Java 17, the most prominent two additions are cgroups v2 support and container awareness in the &lt;code&gt;OperatingSystemMXBean&lt;/code&gt;.&lt;/p&gt; &lt;h3&gt;cgroups v2 support&lt;/h3&gt; &lt;p&gt;Since Java 15, OpenJDK detects the cgroup version in use and detects limits according to cgroup version-specific settings. For Java 15 and onwards, OpenJDK supports cgroups v1 as well as cgroups v2 or the unified hierarchy (see &lt;a href="https://bugs.openjdk.java.net/browse/JDK-8230305"&gt;JDK-8230305&lt;/a&gt; for more on this).&lt;/p&gt; &lt;p&gt;If you run Java 11 or Java 8 on a system that has only cgroups v2 , no container detection will be in place and the host values will be used instead. As explained earlier, this might yield unexpected application behavior in containerized deployments.&lt;/p&gt; &lt;p&gt;One quick way to show which cgroup version is in use on a system is the &lt;code&gt;-XshowSettings:system&lt;/code&gt; option of the &lt;code&gt;java&lt;/code&gt; launcher. (This option is Linux-specific.) Here's an example:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ java -XshowSettings:system -version Operating System Metrics: Provider: cgroupv2 Effective CPU Count: 2 CPU Period: 100000us CPU Quota: 200000us CPU Shares: 1024us List of Processors: N/A List of Effective Processors, 4 total: 0 1 2 3 List of Memory Nodes: N/A List of Available Memory Nodes, 1 total: 0 Memory Limit: 1.00G Memory Soft Limit: 800.00M Memory &amp; Swap Limit: 1.00G openjdk version "17.0.2" 2022-01-18 OpenJDK Runtime Environment 21.9 (build 17.0.2+8) OpenJDK 64-Bit Server VM 21.9 (build 17.0.2+8, mixed mode, sharing)&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Other ways to figure out the cgroup configuration in use include the &lt;code&gt;VM.info&lt;/code&gt; &lt;code&gt;jcmd&lt;/code&gt; utility (in the section "container (cgroup) information") or the &lt;code&gt;-Xlog:os+container=debug&lt;/code&gt; JVM option.&lt;/p&gt; &lt;p&gt;If no cgroup v2 support is present—if you were working with Java 11, for example—the &lt;code&gt;-XshowSettings:system&lt;/code&gt; output would look like this:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ java -XshowSettings:system -version Operating System Metrics: No metrics available for this platform openjdk version "11.0.14" 2022-01-18 OpenJDK Runtime Environment 18.9 (build 11.0.14+9) OpenJDK 64-Bit Server VM 18.9 (build 11.0.14+9, mixed mode, sharing)&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;If no system metrics are detected, the JVM process falls back to using host operating system settings.&lt;/p&gt; &lt;h3&gt;OperatingSystemMXBean container awareness&lt;/h3&gt; &lt;p&gt;Since Java 14, the &lt;code&gt;OperatingSystemMXBean&lt;/code&gt; uses the JDK's internal, Linux-specific Metrics Java API to report system information. That means if cgroup limits are in place, the &lt;code&gt;OperatingSystemMXBean&lt;/code&gt; reports those limits (as appropriate) over the container host system resources. This feature has also been backported to Java 8 (8u272 and newer) and Java 11 (11.0.9 and newer).&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note&lt;/strong&gt;: Container awareness in OpenJDK can be disabled with the in the &lt;code&gt;-XX:-UseContainerSupport&lt;/code&gt; JVM option. This, in turn, would disable container awareness of &lt;code&gt;OperatingSystemMXBean&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;The following file, named &lt;code&gt;CheckOperatingSystemMXBean.java&lt;/code&gt;, displays information about the system on which it is running. As it is using the container-aware &lt;code&gt;OperatingSystemMXBean&lt;/code&gt;, it will show information about either the physical host or the container resources, depending on the environment in which it is running:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;import com.sun.management.OperatingSystemMXBean; import java.lang.management.ManagementFactory; public class CheckOperatingSystemMXBean { public static void main(String[] args) { System.out.println("Checking OperatingSystemMXBean"); OperatingSystemMXBean osBean = (OperatingSystemMXBean) ManagementFactory.getOperatingSystemMXBean(); System.out.println(String.format("Runtime.availableProcessors: %d", Runtime.getRuntime().availableProcessors())); System.out.println(String.format("OperatingSystemMXBean.getAvailableProcessors: %d", osBean.getAvailableProcessors())); System.out.println(String.format("OperatingSystemMXBean.getTotalPhysicalMemorySize: %d", osBean.getTotalPhysicalMemorySize())); System.out.println(String.format("OperatingSystemMXBean.getFreePhysicalMemorySize: %d", osBean.getFreePhysicalMemorySize())); System.out.println(String.format("OperatingSystemMXBean.getTotalSwapSpaceSize: %d", osBean.getTotalSwapSpaceSize())); System.out.println(String.format("OperatingSystemMXBean.getFreeSwapSpaceSize: %d", osBean.getFreeSwapSpaceSize())); System.out.println(String.format("OperatingSystemMXBean.getSystemCpuLoad: %f", osBean.getSystemCpuLoad())); } }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Compiling and running the program displays the resources available to it:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ ./jdk-17.0.1+12/bin/javac CheckOperatingSystemMXBean.java $ sudo podman run -ti --rm --memory 300m --memory-swap 300m --cpu-period 100000 --cpu-quota 200000 -v $(pwd):/opt:z fedora:35 [root@7a0de39d8430 opt]# /opt/jdk-17.0.1+12/bin/java CheckOperatingSystemMXBean Checking OperatingSystemMXBean Runtime.availableProcessors: 2 OperatingSystemMXBean.getAvailableProcessors: 2 OperatingSystemMXBean.getTotalPhysicalMemorySize: 314572800 OperatingSystemMXBean.getFreePhysicalMemorySize: 291680256 OperatingSystemMXBean.getTotalSwapSpaceSize: 0 OperatingSystemMXBean.getFreeSwapSpaceSize: 0 OperatingSystemMXBean.getSystemCpuLoad: 0.050386 [root@7a0de39d8430 opt]# /opt/jdk-17.0.1+12/bin/java -XX:-UseContainerSupport CheckOperatingSystemMXBean Checking OperatingSystemMXBean Runtime.availableProcessors: 4 OperatingSystemMXBean.getAvailableProcessors: 4 OperatingSystemMXBean.getTotalPhysicalMemorySize: 5028548608 OperatingSystemMXBean.getFreePhysicalMemorySize: 3474866176 OperatingSystemMXBean.getTotalSwapSpaceSize: 5027917824 OperatingSystemMXBean.getFreeSwapSpaceSize: 5027917824 OperatingSystemMXBean.getSystemCpuLoad: 0.000000 &lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Tuning defaults for containers&lt;/h2&gt; &lt;p&gt;In some cases, the OpenJDK default settings for memory and CPU usage might not be the desired settings for applications running in containers. OpenJDK needs to consider multi-user desktop and server systems as well as container use cases, among other things. A container is different from a desktop or server because quite often the Java process is the only one running in that container. For example, in a Kubernetes container with a memory limit of 800MB RAM, a default &lt;code&gt;-XX:MaxRAMPercentage=25&lt;/code&gt;, probably doesn't make as much sense as it would on a multi-user desktop system, because the maximum heap size would be bound above by 200MB RAM (one-quarter of 800MB) of that 800MB container.&lt;/p&gt; &lt;p&gt;To tune OpenJDK for the typical container use case, options have been introduced with &lt;a href="https://bugs.openjdk.java.net/browse/JDK-8186248"&gt;JDK-8186248&lt;/a&gt; (and in OpenJDK 8u with &lt;a href="https://bugs.openjdk.java.net/browse/JDK-8146115"&gt;JDK-8146115&lt;/a&gt;) that specifically allow you to set heap sizes in percentages of available (container) memory to better fit this specific use case. These options are &lt;code&gt;-XX:InitialRAMPercentage&lt;/code&gt;, &lt;code&gt;-XX:MaxRAMPercentage&lt;/code&gt;, and &lt;code&gt;-XX:MinRAMPercentage&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Setting these percentage options when the application runs in a container is preferable to setting maximum and minimum heap size for your application via &lt;code&gt;-Xmx&lt;/code&gt; and &lt;code&gt;-Xms&lt;/code&gt;, respectively. The &lt;code&gt;-XX&lt;/code&gt; options set the heap size &lt;em&gt;relative&lt;/em&gt; to the container memory limits and get updated automatically on redeployment should those limits change in the deployment configuration. When both types of settings are in place, &lt;code&gt;-Xmx&lt;/code&gt; and &lt;code&gt;-Xms&lt;/code&gt; take precedence.&lt;/p&gt; &lt;p&gt;Another important option for overriding CPU settings when running inside containers is &lt;code&gt;-XX:ActiveProcessorCount&lt;/code&gt;. This option lets you specify exactly how many CPU cores the JVM should use regardless of container detection heuristics.&lt;/p&gt; &lt;p&gt;Container detection support can also be disabled entirely using the &lt;code&gt;-XX:-UseContainerSupport&lt;/code&gt; option.&lt;/p&gt; &lt;p&gt;Table 1 summarizes some useful options for tuning JVM settings when running in a container.&lt;/p&gt; &lt;div&gt; &lt;table cellspacing="0" width="646"&gt;&lt;caption&gt;Table 1: Tuning options.&lt;/caption&gt; &lt;tbody&gt;&lt;tr&gt;&lt;td&gt; &lt;p&gt;&lt;strong&gt;JVM option&lt;/strong&gt;&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;&lt;strong&gt;Replaces JVM option&lt;/strong&gt;&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;&lt;strong&gt;Description&lt;/strong&gt;&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;&lt;strong&gt;Default value&lt;/strong&gt;&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt; &lt;p&gt;&lt;code&gt;-XX:InitialRAMPercentage&lt;/code&gt;&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;&lt;code&gt;-XX:InitialRAMFraction&lt;/code&gt;&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;Percentage of real memory used for initial heap size&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;1.5625&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt; &lt;p&gt;&lt;code&gt;-XX:MaxRAMPercentage&lt;/code&gt;&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;&lt;code&gt;-XX:MaxRAMFraction&lt;/code&gt;&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;Maximum percentage of real memory used for maximum heap size&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;25&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt; &lt;p&gt;&lt;code&gt;-XX:MinRAMPercentage&lt;/code&gt;&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;&lt;code&gt;-XX:MinRAMFraction&lt;/code&gt;&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;Minimum percentage of real memory used for maximum heap size on systems with small physical memory&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;50&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt; &lt;p&gt;&lt;code&gt;-XX:ActiveProcessorCount&lt;/code&gt;&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;n/a&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;CPU count that the VM should use and report as active&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;n/a&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt; &lt;p&gt;&lt;code&gt;-XX:±UseContainerSupport&lt;/code&gt;&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;n/a&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;Enable detection and runtime container configuration support&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;true&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt; &lt;h2&gt;Opinionated configuration&lt;/h2&gt; &lt;p&gt;Default container detection heuristics for CPU resource limits are largely modeled on the way popular container orchestration frameworks—specifically Kubernetes and Mesos—spawn containers. For example, in a Kubernetes setup, there are four (main) cases to consider when CPU resource limits are in place. There are actually even more possibilities because cluster defaults might be in place, but those are largely also covered by these cases:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Both &lt;code&gt;spec.containers[].resources.limits.cpu&lt;/code&gt; and &lt;code&gt;spec.containers[].resources.requests.cpu&lt;/code&gt; are explicitly set.&lt;/li&gt; &lt;li&gt;Only &lt;code&gt;spec.containers[].resources.limits.cpu&lt;/code&gt; is explicitly set. Kubernetes sets &lt;code&gt;spec.containers[].resources.requests.cpu&lt;/code&gt; to the same value as &lt;code&gt;spec.containers[].resources.limits.cpu&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;Only &lt;code&gt;spec.containers[].resources.requests.cpu&lt;/code&gt; is explicitly set. Kubernetes sets &lt;code&gt;spec.containers[].resources.limits.cpu&lt;/code&gt; to a value not smaller than &lt;code&gt;spec.containers[].resources.requests.cpu&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;Neither &lt;code&gt;spec.containers[].resources.limits.cpu&lt;/code&gt; nor &lt;code&gt;spec.containers[].resources.requests.cpu&lt;/code&gt; is set. Kubernetes keeps &lt;code&gt;spec.containers[].resources.limits.cpu&lt;/code&gt; unset and sets &lt;code&gt;spec.containers[].resources.requests.cpu&lt;/code&gt; to 2 if no other defaults are in place.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;Container orchestration frameworks usually multiply the millicore value of &lt;code&gt;spec.containers[].resources.requests.cpu&lt;/code&gt; by 1024, which then directly translates to the value set in Docker or Podman by the &lt;code&gt;--cpu-shares&lt;/code&gt; command-line option. Therefore, the JVM will calculate the CPU shares value based on this knowledge.&lt;/p&gt; &lt;p&gt;In addition, the JVM will set a lower bound on a CPU core value of 1. That is, a container with a setting of &lt;code&gt;spec.containers[].resources.requests.cpu=500m&lt;/code&gt; makes the JVM use a single CPU core (&lt;code&gt;0.5 * 1024 = 512&lt;/code&gt;, generating an option of &lt;code&gt;--cpu-shares=512&lt;/code&gt;; &lt;code&gt;cpu-shares &lt; 1024&lt;/code&gt; results in one core). A setting of &lt;code&gt;spec.containers[].resources.requests.cpu=2&lt;/code&gt; makes the JVM use two CPU cores, and so on.&lt;/p&gt; &lt;p&gt;Note that these rules cause the JVM to think it can use only one CPU core for the final case in the list, where neither option is explicitly set. In such a case, it is recommended that you override the desired CPU core value via &lt;code&gt;-XX:ActiveProcessorCount&lt;/code&gt;.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note:&lt;/strong&gt; In versions 18.0.2 and newer, OpenJDK will no longer take CPU shares settings into account for its calculation of available CPU cores. See &lt;a href="https://bugs.openjdk.java.net/browse/JDK-8281181"&gt;JDK-8281181&lt;/a&gt; for details.&lt;/p&gt; &lt;p&gt;The &lt;code&gt;spec.containers[].resources.limits.cpu&lt;/code&gt; (L) millicore value directly translates to Docker's and Podman's &lt;code&gt;--cpu-quota&lt;/code&gt; (Q) and &lt;code&gt;--cpu-period&lt;/code&gt; (P) values. The JVM will calculate the limit—as set by (L)—based on the formula &lt;code&gt;ceil(Q/P)&lt;/code&gt;. Note that if &lt;em&gt;both&lt;/em&gt; &lt;code&gt;spec.containers[].resources.limits.cpu&lt;/code&gt; and &lt;code&gt;spec.containers[].resources.requests.cpu&lt;/code&gt; are specified, the &lt;code&gt;limits&lt;/code&gt; value takes precedence. This will make the JVM use reasonable values for CPU cores in the first three cases. To prefer shares over CPU quota, specify the &lt;code&gt;-XX:-PreferContainerQuotaForCPUCount&lt;/code&gt; option (see &lt;a href="https://bugs.openjdk.java.net/browse/JDK-8197867"&gt;JDK-8197867&lt;/a&gt; for more on this).&lt;/p&gt; &lt;p&gt;Similarly, resource limits for RAM exist via container orchestration frameworks. &lt;code&gt;spec.containers[].resources.limits.memory&lt;/code&gt; translates to the &lt;code&gt;–memory&lt;/code&gt; and &lt;code&gt;–memory-swap&lt;/code&gt; command-line options of container engines. &lt;code&gt;spec.containers[].resources.requests.memory&lt;/code&gt; usually doesn't have an effect on the spawned containers. On nodes using cgroup v2, &lt;code&gt;memory.min&lt;/code&gt; or &lt;code&gt;memory.low&lt;/code&gt; might be set accordingly. Memory request settings have no effect on the JVM side other than reporting those values for diagnostics.&lt;/p&gt; &lt;h2&gt;Diagnostic options for debugging&lt;/h2&gt; &lt;p&gt;Trace logs can be quite useful for helping you better understand what OpenJDK's container detection logic is doing. Note that there are two different implementations of the detection logic: One for the JVM (&lt;code&gt;libjvm.so&lt;/code&gt;) and another implemented in Java for use of core libraries.&lt;/p&gt; &lt;p&gt;The JVM's container detection logic is integrated with the unified logging framework and can be traced for example via &lt;code&gt;-Xlog:os+container=trace&lt;/code&gt;. For OpenJDK 8u JVMs, the rough equivalent is &lt;code&gt;-XX:+UnlockDiagnosticVMOptions -XX:+PrintContainerInfo&lt;/code&gt;. These traces print whether or not container detection is actually working and what values the JVM is determining to be in place by inspecting the cgroup pseudo filesystem of a deployed application.&lt;/p&gt; &lt;p&gt;For Java 11+ it's also useful to know which GC is being used, and you can display this information via &lt;code&gt;-Xlog:gc=info&lt;/code&gt;. For example, when container limits allow only a single CPU to be active, the Serial GC will be selected. If more than one CPU is active and sufficient memory (at least 2GB) is allocated to the container, the G1 GC will be selected in Java 11 and later versions:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ java -XX:ActiveProcessorCount=1 -Xlog:gc=info -version [0.048s][info][gc] Using Serial openjdk version "17.0.1" 2021-10-19 OpenJDK Runtime Environment 21.9 (build 17.0.1+12) OpenJDK 64-Bit Server VM 21.9 (build 17.0.1+12, mixed mode, sharing) $ java -Xlog:gc=info -version [0.006s][info][gc] Using G1 openjdk version "17.0.1" 2021-10-19 OpenJDK Runtime Environment 21.9 (build 17.0.1+12) OpenJDK 64-Bit Server VM 21.9 (build 17.0.1+12, mixed mode, sharing)&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Other options include the &lt;code&gt;VM.info&lt;/code&gt; &lt;code&gt;jcmd&lt;/code&gt; utility, which is useful for determining the container detection settings of an already running Java process. The cgroup information shown via &lt;code&gt;VM.info&lt;/code&gt; is the same information recorded in &lt;code&gt;hs_err*.log&lt;/code&gt; files when the JVM crashes.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note:&lt;/strong&gt; Most of this information is also available via &lt;a href="https://developers.redhat.com/blog/2020/08/25/get-started-with-jdk-flight-recorder-in-openjdk-8u"&gt;JDK Flight Recorder&lt;/a&gt; (JFR), a powerful tool for diagnosing issues. In containers, JFR information can be accessed via &lt;a href="https://developers.redhat.com/blog/2021/01/25/introduction-to-containerjfr-jdk-flight-recorder-for-containers"&gt;Cryostat&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;For more information on how the Kubernetes deployment configuration can have an effect on OpenJDK's selection of a GC algorithm on a cgroups v2 system, check out my screencast on this topic:&lt;/p&gt; &lt;div class="video-embed-field-provider-youtube video-embed-field-responsive-video"&gt; &lt;/div&gt; &lt;p&gt;The screencast demonstrates that OpenJDK might behave slightly differently depending on your application's deployment in a container. With the help of this article, you can now make more sense of why. Feel free to tune your application's container settings so as to get the most out of your cloud deployment. Keep in mind that cgroup v2 support is only available in Java 17+ for now, although it will also be in OpenJDK 11u soon.&lt;/p&gt; &lt;p&gt;If you're interested in learning more about the ins and outs of fine-tuning Java in container-based environments, read the first article in this series, &lt;a href="https://developers.redhat.com/articles/2022/03/08/java-single-core-containers"&gt;Java in single-core containers&lt;/a&gt;, or check out &lt;a href="https://developers.redhat.com/articles/2021/11/23/faster-way-access-jdk-flight-recorder-data"&gt;Red Hat Developer's recent series on Cryostat&lt;/a&gt;. You can also watch &lt;a href="https://developers.redhat.com/devnation/tech-talks/java-and-containers"&gt;Java and containers: What's there to think about?&lt;/a&gt;, a DevNation Tech Talk from Christine Flood and Edson Yanaga.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/04/19/java-17-whats-new-openjdks-container-awareness" title="Java 17: What’s new in OpenJDK's container awareness"&gt;Java 17: What’s new in OpenJDK's container awareness&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Severin Gehwolf</dc:creator><dc:date>2022-04-19T07:00:00Z</dc:date></entry></feed>
